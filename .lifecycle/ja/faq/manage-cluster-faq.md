---
title: TiDBクラスターの管理FAQ
summary: TiDBクラスターの管理に関連するFAQについて学びます。
---

# TiDBクラスターの管理FAQ

この文書は、TiDBクラスターの管理に関連するFAQをまとめたものです。

## 日常管理

このセクションでは、日常のクラスター管理中に遭遇する可能性のある一般的な問題、それらの原因、および解決策について説明します。

### TiDBにログインする方法は？

MySQLにログインするのと同様にTiDBにログインできます。例：

```bash
mysql -h 127.0.0.1 -uroot -P4000
```

### TiDBのシステム変数をどのように変更しますか？

MySQLと同様に、TiDBには静的および固有のパラメータが含まれています。静的パラメータは `SET GLOBAL xxx = n` を使用して直接変更できますが、パラメータの新しい値はこのインスタンスのライフサイクル内でのみ有効です。

### TiDB（TiKV）のデータディレクトリはどこですか、およびどんなものですか？

TiKVのデータは [`--data-dir`](/command-line-flags-for-tikv-configuration.md#--data-dir) にあり、これにはバックアップ、DB、Raft、およびスナップの4つのディレクトリが含まれており、それぞれバックアップ、データ、Raftデータ、およびミラーデータを保存するために使用されます。

### TiDBにはどのようなシステムテーブルがありますか？

MySQLと同様に、TiDBにはサーバーが実行される際に必要な情報を保存するためのシステムテーブルが含まれています。[TiDBシステムテーブル](/mysql-schema.md)を参照してください。

### TiDB/PD/TiKVのログはどこにありますか？

デフォルトでは、TiDB/PD/TiKVはログに標準エラーを出力します。起動時に `--log-file` でログファイルが指定されている場合、ログは指定されたファイルに出力され、毎日ローテーションが実行されます。

### TiDBを安全に停止するには？

- ロードバランサーが実行されている場合（推奨）：ロードバランサーを停止し、SQLステートメント `SHUTDOWN` を実行します。その後、TiDBは[`graceful-wait-before-shutdown`](/tidb-configuration-file.md#graceful-wait-before-shutdown-new-in-v50) で指定された期間まで待機し、すべてのセッションが終了するまで待機します。その後、TiDBは停止します。

- ロードバランサーが実行されていない場合：`SHUTDOWN` ステートメントを実行します。その後、TiDBコンポーネントは正常に停止します。

### TiDBで `kill` を実行できますか？

- DMLステートメントをキルする:

    まず `information_schema.cluster_processlist` を使用してTiDBインスタンスのアドレスとセッションIDを見つけ、次にkillコマンドを実行します。

    TiDB v6.1.0ではグローバルキル機能（`enable-global-kill` 構成によって制御され、デフォルトでは有効になっています）が導入されました。グローバルキルが有効になっている場合、単純に `kill session_id` を実行します。

    TiDBのバージョンがv6.1.0よりも古い場合、またはグローバルキル機能が無効になっている場合、デフォルトで `kill session_id` は効果を発揮しません。DMLステートメントを終了するには、クライアントを直接実行しているTiDBインスタンスにクライアントを接続し、次に `kill tidb session_id` ステートメントを実行する必要があります。クライアントが他のTiDBインスタンスに接続しているか、クライアントとTiDBクラスターの間にプロキシがある場合、 `kill tidb session_id` ステートメントは誤って別のセッションを終了する可能性があります。詳細については、[`KILL`](/sql-statements/sql-statement-kill.md)を参照してください。

- DDLステートメントをキルする: まず、`admin show ddl jobs` を使用して終了する必要のあるDDLジョブのIDを検索し、次に `admin cancel ddl jobs 'job_id' [, 'job_id'] ...` を実行します。詳細については[`ADMIN` ステートメント](/sql-statements/sql-statement-admin.md)を参照してください。

### TiDBはセッションタイムアウトをサポートしていますか？

TiDBは現在、[`wait_timeout`](/system-variables.md#wait_timeout) と [`interactive_timeout`](/system-variables.md#interactive_timeout) の2つのタイムアウトをサポートしています。

### TiDBのバージョン管理戦略は何ですか？

TiDBバージョン管理の詳細については、[TiDBバージョニング](/releases/versioning.md) を参照してください。

### TiDBクラスターをデプロイおよび維持する運用コストはどのようですか？

TiDBには、いくつかの機能と[ツール](/ecosystem-tool-user-guide.md)が用意されており、これらを使用することで低コストでクラスターを簡単に管理できます。

- メンテナンス操作には、デプロイ、スケーリング、アップグレード、その他のメンテナンスタスクを簡素化するパッケージマネージャーとして動作する[TiUP](/tiup/tiup-documentation-guide.md) が使用できます。
- 監視には、[TiDB監視フレームワーク](/tidb-monitoring-framework.md)があります。これは[Prometheus](https://prometheus.io/) を使用して監視およびパフォーマンスメトリクスを保存し、[Grafana](https://grafana.com/grafana/) を使用してこれらのメトリクスを視覚化します。数十の組み込みパネルが用意され、数百のメトリクスが利用可能です。
- トラブルシューティングには、[TiDBトラブルシューティングマップ](/tidb-troubleshooting-map.md)があります。これはTiDBサーバーおよびその他のコンポーネントの一般的な問題をまとめたもので、関連する問題が発生した場合に診断および解決に使用できます。

### TiDBマスターバージョン間の違いは何ですか？

TiDBコミュニティは非常に活発です。エンジニアたちは機能の最適化とバグの修正を続けています。そのため、TiDBバージョンは非常に速く更新されます。最新バージョンの情報を常に知りたい場合は、[TiDBリリースタイムライン](/releases/release-timeline.md)を参照してください。

TiDBを[使用してデプロイする](/production-deployment-using-tiup.md)か、[TiDBオペレータを使用する](https://docs.pingcap.com/tidb-in-kubernetes/stable)ことをお勧めします。TiDBでは、バージョン番号の統一された管理が行われています。次のいずれかの方法でバージョン番号を表示できます。

- `select tidb_version()`
- `tidb-server -V`

### TiDBのグラフィカルデプロイツールはありますか？

現在はありません。

### TiDBクラスターのスケールアウト方法は？

オンラインサービスを中断することなくTiDBクラスターをスケールアウトできます。

- TiUPを使用してクラスターがデプロイされている場合は、[TiUPを使用してTiDBクラスターをスケールアウトする](/scale-tidb-using-tiup.md)を参照してください。
- Kubernetes上で[TiDBオペレータ](/tidb-operator-overview.md)を使用してクラスターがデプロイされている場合は、[Kubernetes上でTiDBを手動でスケールアウトする](https://docs.pingcap.com/tidb-in-kubernetes/stable/scale-a-tidb-cluster)を参照してください。

### TiDBを水平にスケールする方法は？

ビジネスが成長するにつれて、データベースは次の3つのボトルネックに直面するかもしれません。

- ディスク容量が不足していること、つまりディスク容量が足りないこと。

- 高CPU占有率など、計算リソースが不足していること。

- 書き込みおよび読み取りキャパシティが不足していること。

ビジネスが成長するにつれて、TiDBをスケールアウトできます。

- ディスク容量が不足している場合、簡単にTiKVノードを追加することで容量を増やせます。新しいノードが起動されると、PDはデータを自動的に新しいノードに移行します。

- 計算リソースが不足している場合は、TiDBノードまたはTiKVノードを追加する前にCPUの利用状況を確認します。TiDBノードを追加すると、ロードバランサーで構成できます。

- キャパシティが不足している場合、TiDBノードとTiKVノードの両方を追加することができます。

### パーコレーターが分散ロックを使用し、クラッシュしたクライアントがロックを保持している場合、ロックは解放されないのですか？

詳細については、[パーコレーターとTiDBトランザクションアルゴリズム](https://pingcap.com/blog-cn/percolator-and-txn/)を参照してください。

### なぜTiDBはThriftの代わりにgRPCを使用しているのですか？Googleが使用しているからですか？

実際にはそうではありません。gRPCのような優れた機能が必要だからです。例えば、フロー制御、暗号化、ストリーミングなどが挙げられます。

### `like(bindo.customers.name, jason%, 92)` の92は何を示していますか？

92はエスケープ文字を示し、デフォルトでASCII 92です。

### `information_schema.tables.data_length` で表示されるデータ長がTiKV監視パネルのストアサイズと異なるのはなぜですか？

2つの理由があります：

- 2つの結果は異なる方法で計算されています。 `information_schema.tables.data_length` は各行の平均長を計算して推定された値ですが、TiKV監視パネルのストアサイズは（RocksDBのSSTファイルである）データファイルの長さをTiKVインスタンス内で集計したものです。
- `information_schema.tables.data_length` は論理値であり、ストアサイズは物理値です。トランザクションの複数のバージョンによって生成された冗長なデータは論理値に含まれませんが、冗長なデータは物理値においてTiKVで圧縮されています。

### トランザクションが非同期コミットまたはワンフェーズコミット機能を使用しないのはなぜですか？

次の状況では、[非同期コミット](/system-variables.md#tidb_enable_async_commit-new-in-v50) 機能と [ワンフェーズコミット](/system-variables.md#tidb_enable_1pc-new-in-v50) 機能を有効にしていても、TiDBはこれらの機能を使用しません：

- TiDB Binlogが有効になっている場合、TiDB Binlogの実装制限により、TiDBは非同期コミットまたはワンフェーズコミット機能を使用しません。
- トランザクションに書き込まれるキーバリューペアが256個を超えない場合、およびキーの総サイズが4 KBを超えない場合にのみ、TiDBは非同期コミットまたはワンフェーズコミット機能を使用します。これは、大量のデータを書き込むトランザクションでは、非同期コミットを使用してもパフォーマンスが大幅に向上しないためです。

## PD管理
```
このセクションでは、PD管理中に遭遇する可能性のある一般的な問題、それらの原因、および解決策について説明します。

### PDにアクセスすると`TiKVクラスターがブートストラップされていません`というメッセージが表示されます

PDのほとんどのAPIは、TiKVクラスターが初期化されている場合にのみ利用可能です。新しいクラスターが展開された場合、PDが開始された状態でTiKVが開始されていないときにPDにアクセスすると、このメッセージが表示されます。このメッセージが表示された場合は、TiKVクラスターを開始してください。TiKVが初期化されると、PDにアクセスできます。

### PDを起動する際に`etcdクラスターIDの不一致`というメッセージが表示されます

これは、PDの起動パラメーターの`--initial-cluster`に、このクラスターに属さないメンバーが含まれているためです。この問題を解決するには、各メンバーの対応するクラスターを確認し、誤ったメンバーを削除した後、PDを再起動してください。

### PDの時刻同期エラーの最大許容誤差はどのくらいですか？

PDは同期エラーを許容できますが、より大きなエラー値はPDによって割り当てられたタイムスタンプと物理時間の間により大きな隔たりを生じさせ、履歴バージョンの読み取りなどの機能に影響を与えます。

### クライアント接続はPDをどのように見つけるのですか？

クライアント接続はTiDBを介してのみクラスターにアクセスできます。TiDBはPDとTiKVに接続します。PDとTiKVはクライアントに対しては透過的です。TiDBが任意のPDに接続する際、PDはTiDBに現在のリーダーが誰かを伝えます。もしPDが現在のリーダーでない場合、TiDBはリーダーのPDに再接続します。

### TiKVストアの各ステータス（Up、Disconnect、Offline、Down、Tombstone）の関係は何ですか？

各ステータスの関係については、[TiKVストアの各ステータスの関係](/tidb-scheduling.md#information-collection)を参照してください。

TiKVストアのステータス情報を確認するには、PD Controlを使用できます。

### PDの`scheduler.limit-leader`と`scheduler.region-schedule-limit`のスケジューリングパラメータの違いは何ですか？

- `scheduler.limit-leader`スケジューリングパラメータは、異なるTiKVサーバーのリーダー数を均等にするために使用され、クエリ処理の負荷に影響します。
- `scheduler.region-schedule-limit`スケジューリングパラメータは、異なるTiKVサーバーのレプリカ数を均等にするために使用され、異なるノードのデータ量に影響します。

### 各リージョンのレプリカ数は設定可能ですか？可能な場合、設定方法は？

はい。現在は、グローバルなレプリカ数のみを更新できます。最初に起動する際、PDは設定ファイル（conf/pd.yml）を読み取り、その中のmax-replicas構成を使用します。後で数を更新する場合は、pd-ctl構成コマンド`config set max-replicas $num`を使用してください。有効な構成を`config show all`で表示し、更新はアプリケーションに影響を与えず、背後で構成されます。

設定するレプリカ数の合計が常に、設定するレプリカ数以上のTiKVインスタンスの数以上であることを確認してください。例えば、3つのレプリカには少なくとも3つのTiKVインスタンスが必要です。レプリカ数を増やす前に追加のストレージ要件を見積もる必要があります。pd-ctlに関する詳細は、[PD Controlユーザーガイド](/pd-control.md)を参照してください。

### コマンドラインクラスタ管理ツールが不足している場合のクラスタ全体の健康状態を確認する方法は？

pd-ctlツールを使用してクラスターの一般的な状態を判断できます。詳細なクラスターの状態を確認するには、モニタを使用する必要があります。

### オフラインになったクラスターノードの監視データをどのように削除しますか？

オフラインノードは通常TiKVノードを示します。pd-ctlまたはモニタを使用して、オフラインプロセスが完了したかどうかを確認できます。ノードがオフラインになった後は、次の手順を実行してください：

1. オフラインノードで関連するサービスを手動で停止します。
2. Prometheus構成ファイルから対応するノードの`node_exporter`データを削除します。

## TiDBサーバー管理

このセクションでは、TiDBサーバー管理中に遭遇する可能性のある一般的な問題、それらの原因、および解決策について説明します。

### TiDBで`lease`パラメータを設定する方法は？

leaseパラメータ（`--lease=60`）は、TiDBサーバーを起動する際にコマンドラインから設定されます。leaseパラメータの値は、現在のセッションのデータベーススキーマ変更（DDL）の速度に影響を与えます。テスト環境では、テストサイクルを加速するために値を1秒に設定できますが、本番環境ではDDLの安全性を確保するために値を分単位（例えば60）に設定することを推奨します。

### DDL操作の処理時間はどのくらいですか？

処理時間は異なるシナリオによって異なります。一般的に、次の3つのシナリオを考慮できます：

1. 対応するデータテーブルの行数が比較的少ない`Add Index`操作：約3秒
2. 対応するデータテーブルの行数が比較的多い`Add Index`操作：処理時間は特定の行数とその時点でのQPSに依存します（`Add Index`操作は通常のSQL操作よりも低い優先順位です）
3. その他のDDL操作：約1秒

DDLリクエストを受け取ったTiDBサーバーインスタンスがDDLオーナーが存在するTiDBサーバーインスタンスである場合、上記の最初と三番目のシナリオは通常、数十から数百ミリ秒だけかかることがあります。

### 時々DDLステートメントの実行が非常に遅いのはなぜですか？

可能な理由：

- 複数のDDLステートメントを同時に実行する場合、最後の数個のDDLステートメントが遅く実行される場合があります。これは、DDLステートメントがTiDBクラスターで直列に実行されるためです。
- クラスターを正常に起動した後、最初のDDL操作は通常約30秒かかることがあります。これは、TiDBクラスターがDDLステートメントを処理するリーダーを選出しているためです。
- TiDBがTiDBの停止時に通常通信できない場合（電源障害を含む）、または`kill -9`コマンドによってTiDBが停止され、TiDBがPDから登録データを適切に削除できなかった場合、起動後の初めての10分間のDDLステートメントの処理時間は通常よりもはるかに長くなります。この場合、各DDLの状態変更には2 * lease（lease = 45秒）を待つ必要があります。
- TiDBサーバーとクラスター内のPDサーバー間で通信の問題が発生した場合、TiDBサーバーはPDサーバーからバージョン情報をうまく取得または更新できません。この場合、各DDLの状態処理には2 * leaseを待つ必要があります。

### TiDBでS3をバックエンドストレージエンジンとして利用できますか？

いいえ。現在、TiDBは分散ストレージエンジンとGoleveldb/RocksDB/BoltDBエンジンのみをサポートしています。

### `Information_schema`はより実際の情報をサポートできますか？

MySQL互換性の一環として、TiDBは多くの`INFORMATION_SCHEMA`テーブルをサポートしています。これらのテーブルの多くには、対応するSHOWコマンドもあります。詳細については、[Information Schema](/information-schema/information-schema.md)を参照してください。

### TiDB Backoffのタイプシナリオの説明は何ですか？

TiDBサーバーとTiKVサーバー間の通信プロセスで、大量のデータを処理しているときに、`Server is busy`または`backoff.maxsleep 20000ms`ログメッセージが表示されることがあります。これは、TiKVサーバーがデータを処理しているときにシステムがビジー状態であるためです。この場合、通常、TiKVホストのリソース使用率が高いことがわかります。このような場合、リソース使用率に応じてサーバー容量を増やすことができます。

### TiDB TiClientのタイプの主な原因は何ですか？

TiClientリージョンエラーインジケーターは、TiDBサーバーがクライアントとしてTiKVサーバーにアクセスし、KVインターフェースを介してデータ操作を行う際に表示されるエラータイプとメトリクスを説明します。エラータイプには`not_leader`や`stale_epoch`が含まれます。これらのエラーは、TiDBサーバーが独自のキャッシュ情報に基づいてリージョンリーダーデータを操作する場合、リージョンリーダーが移行された場合、またはTiDBキャッシュのTiKVリージョン情報とルーティング情報が不一致の場合に発生します。通常、この場合、TiDBサーバーは自動的にPDから最新のルーティングデータを取得し、以前の操作をやり直します。

### TiDBがサポートする同時接続の最大数は何ですか？

デフォルトでは、TiDBサーバーごとの最大接続数に制限はありません。必要に応じて、`config.toml`ファイル内の`instance.max_connections`を設定するか、システム変数[`max_connections`](/system-variables.md#max_connections)の値を変更することで、最大接続数を制限できます。過剰な並行性が応答時間の増加をもたらす場合は、TiDBノードを追加することで容量を増やすことが推奨されます。

### テーブルの作成時刻はどのように表示されますか？

`information_schema`のテーブルの`create_time`が作成時刻です。

### TiDBロ​​グの`EXPENSIVE_QUERY`の意味は何ですか？

TiDBがSQLステートメントを実行しているとき、各演算子が10,000行以上と推定されると、クエリは`EXPENSIVE_QUERY`になります。しきい値を調整するには`tidb-server`構成パラメータを変更してから、`tidb-server`を再起動してください。

### TiDBのテーブルのサイズを見積もる方法は？

TiDBのテーブルのサイズを見積もるには、次のクエリ文を使用できます。
```sql
SELECT
  db_name,
  table_name,
  ROUND(SUM(total_size / cnt), 2) Approximate_Size,
  ROUND(
    SUM(
      total_size / cnt / (
        SELECT
          ROUND(AVG(value), 2)
        FROM
          METRICS_SCHEMA.store_size_amplification
        WHERE
          value > 0
      )
    ),
    2
  ) ディスクサイズ
FROM
  (
    SELECT
      db_name,
      table_name,
      region_id,
      SUM(Approximate_Size) total_size,
      COUNT(*) cnt
    FROM
      information_schema.TIKV_REGION_STATUS
    WHERE
      db_name = @dbname
      AND table_name IN (@table_name)
    GROUP BY
      db_name,
      table_name,
      region_id
  ) tabinfo
GROUP BY
  db_name,
  table_name;
```

上記のステートメントを使用する場合は、ステートメント内の次のフィールドを適切に入力して置き換える必要があります。

- `@dbname`：データベースの名前。
- `@table_name`：対象テーブルの名前。

また、上記のステートメントでは次のようなことが示されています：

- `store_size_amplification` は、クラスターの平均圧縮率を示しています。この情報をクエリするには、`SELECT * FROM METRICS_SCHEMA.store_size_amplification;` を使用することもできますが、**Grafana モニタリング PD - 統計バランス** パネルで各ノードの**Size amplification** メトリクスを確認することもできます。クラスターの平均圧縮率は、すべてのノードの Size amplification の平均です。
- `Approximate_Size` は、圧縮前のレプリカ内のテーブルのサイズを示しています。これは正確な値ではなく、おおよその値であることに注意してください。
- `Disk_Size` は、圧縮後のテーブルのサイズを示しています。これはおおよその値であり、`Approximate_Size` と `store_size_amplification` によって計算することができます。

## TiKV サーバーの管理

このセクションでは、TiKV サーバーの管理中に遭遇するかもしれない一般的な問題、その原因、および解決策について説明します。

### コンプライアンスやマルチテナントアプリケーション向けのデータの場所を指定する方法は？

[Placement Rules](/placement-rules-in-sql.md) を使用して、コンプライアンスやマルチテナントアプリケーション向けのデータの場所を指定できます。

SQL における Placement Rules は、レプリカの数、Raft ロール、配置位置、およびルールが適用されるキー範囲など、任意の連続データ範囲の属性を制御するために設計されています。

### TiKV クラスターにおける推奨されるレプリカの数は何ですか？高可用性のために最小限の数を保つほうが良いですか？

各 Region のために 3 つのレプリカがテスト環境では十分です。ただし、本番シナリオでは決して 3 つ未満のノードで TiKV クラスターを運用してはいけません。インフラストラクチャ、ワークロード、および信頼性の必要性によって、この数を増やしたくなることがあります。コピーが多いほどパフォーマンスは低下しますが、セキュリティは向上します。

### TiKV を起動する際に `クラスター ID の不一致` メッセージが表示される理由

これは、ローカルの TiKV に保存されているクラスター ID が PD で指定されたクラスター ID と異なるためです。新しい PD クラスターを展開すると、PD はランダムなクラスター ID を生成します。TiKV は初期化される際に、PD からクラスター ID を取得し、ローカルにクラスター ID を保存します。次回 TiKV が起動されると、ローカルのクラスター ID を PD のクラスター ID と比較します。もしクラスター ID が一致しない場合は、`クラスター ID 不一致` メッセージが表示され、TiKV は終了します。

以前に PD クラスターを展開していたが、その後 PD のデータを削除して新しい PD クラスターを展開した場合、このエラーが発生します。

### TiKV を起動する際に `重複したストアアドレス` メッセージが表示される理由

これは、起動パラメータのアドレスが他の TiKV によって PD クラスターに登録されているためです。このエラーが発生する一般的な条件：TiKV `--data-dir` で指定されたパスにデータフォルダがない場合（削除したり移動した後に --data-dir を更新していない）、以前のパラメータで TiKV を再起動してしまった場合です。 pd-ctl の [store delete](https://github.com/pingcap/pd/tree/55db505e8f35e8ab4e00efd202beb27a8ecc40fb/tools/pd-ctl#store-delete--label--weight-store_id----jqquery-string) 機能を試して、以前のストアを削除してから TiKV を再起動してください。

### TiKV のプライマリノードとセカンダリノードで同じ圧縮アルゴリズムを使用しているのに、なぜ結果が異なるのですか？

TiKV プライマリノードの一部のファイルは、基礎となるデータの分布および RocksDB の実装に依存して、より高い圧縮率を持っています。データサイズが時折変動するのは正常です。基礎ストレージエンジンは必要に応じてデータを調整します。

### TiKV ブロックキャッシュの特徴は何ですか？

TiKV は RocksDB の Column Family（CF）機能を実装しています。デフォルトでは、KV データは RocksDB 内の 3 つの CF（デフォルト、書き込み、ロック）に最終的に格納されます。

- デフォルト CF は実データを格納し、対応するパラメータは `[rocksdb.defaultcf]` にあります。
- 書き込み CF はデータバージョン情報（MVCC）およびインデックス関連データを格納し、対応するパラメータは `[rocksdb.writecf]` にあります。
- ロック CF はロック情報を格納し、システムはデフォルトのパラメータを使用します。
- Raft RocksDB インスタンスは Raft ログを格納します。デフォルト CF は主に Raft ログを格納し、対応するパラメータは `[raftdb.defaultcf]` にあります。
- すべての CF はデータブロックをキャッシュして RocksDB の読み取り速度を向上させるための共有ブロックキャッシュを持っています。このブロックキャッシュのサイズは `block-cache-size` パラメータで制御されます。パラメータの値が大きいほど、より多くのホットデータがキャッシュされ、また読み込み操作に有利になりますが、システムメモリを消費します。
- 各 CF は個々の書き込みバッファを持ち、そのサイズは `write-buffer-size` パラメータで制御されます。

なぜ TiKV チャネルがいっぱいですか？

- Raftstore スレッドが遅すぎるか、I/O でブロックされています。Raftstore の CPU 使用状況を表示できます。
- TiKV が忙しすぎて（CPU およびディスク I/O など）、処理を行う余裕がありません。

なぜ TiKV が頻繁にリージョンリーダーを切り替えるのでしょうか？

- ネットワークの問題によりノード間の通信が詰まっています。Report failures モニタリングを確認できます。
- 元のメインリーダーのノードが詰まっており、Follower にタイムリーに到達できないため、失敗が発生します。
- Raftstore スレッドが詰まっています。

ノードがダウンした場合、サービスに影響が出るのでしょうか？もし影響が出る場合、どのくらいですか。

TiKV は Raft を使用してデータを複数のレプリカ間でレプリケートします（各リージョンにはデフォルトで 3 つのレプリカがあります）。1 つのレプリカが誤作動した場合、他のレプリカがデータの安全性を保証できます。Raft プロトコルに基づいて、単一のリーダーがダウンすると、2 * リース時間（リース時間は 10 秒）を最大限にして、別のノードのフォロワーがすぐにリージョンリーダーに選出されます。

I/O、メモリ、CPU が高くてパラメータの設定を超える TiKV シナリオは何ですか？

TiKV で大量のデータを書き込みまたは読み込むと、高い I/O、メモリ、および CPU を必要とします。非常に複雑なクエリを実行する場合、大きな中間結果セットが生成されるシナリオなど、大量のメモリや CPU リソースを消費することがあります。

TiKV は SAS/SATA ディスクまたは SSD/SAS ディスクの混在デプロイメントをサポートしていますか？

いいえ。OLTP シナリオでは、TiDB はデータアクセスと操作に高いI/Oディスクを必要とします。強力な整合性を持つ分散データベースとして、TiDB にはレプリカレプリケーションやボトムレイヤーストレージの圧縮など、いくつかの書き込み増幅があります。そのため、TiDB のベストプラクティスではストレージディスクとして NVMe SSD の使用を推奨しています。TiKV と PD の混在デプロイはサポートされていません。

キーのデータテーブルの範囲はアクセス前に分割されますか？

いいえ。これは MySQL のテーブル分割ルールとは異なります。TiKV では、テーブルの範囲はリージョンのサイズに基づいて動的に分割されます。

リージョンはどのように分割されますか？

リージョンは事前に分割されるのではなく、リージョンの分割メカニズムに従います。リージョンのサイズが `region-max-size` または `region-max-keys` の値を超えると、分割がトリガーされます。分割後は、その情報は PD に報告されます。

TiKV には、MySQL の `innodb_flush_log_trx_commit` パラメータのようなデータのセキュリティを保証するためのパラメータがありますか？

はい。現在、スタンドアロンストレージエンジンは 2 つの RocksDB インスタンスを使用しています。1 つのインスタンスは Raft ログを保存するために使用されます。TiKV の `sync-log` パラメータが true に設定されている場合、各コミットは必ず Raft ログにフラッシュされます。クラッシュが発生した場合、Raft ログを使用して KV データを復元することができます。

WAL ストレージのための推奨されるサーバー構成は、SSD、RAID レベル、RAID カードのキャッシュ戦略、NUMA 構成、ファイルシステム、オペレーティングシステムの I/O スケジューリング戦略は何ですか？

WAL は順次書き込みに属するため、これに固有の構成は適用されません。おすすめの構成は以下の通りです：

- SSD
- RAID 10 が好ましい
- RAID カードのキャッシュ戦略とオペレーティングシステムの I/O スケジューリング戦略：現在、特に最適なベストプラクティスはありません；Linux 7 以降ではデフォルトの設定を使用できます
- NUMA：特に具体的な提案はありません；メモリの割り当て戦略については `interleave = all` を使用できます
- ファイルシステム：ext4

最も厳格なデータ利用モード（`sync-log = true`）での書き込みパフォーマンスはどのようにですか？

一般的に、`sync-log` を有効にするとパフォーマンスが約 30% 低下します。`sync-log` を `false` に設定した場合の書き込みパフォーマンスについては、[Sysbench を使用した TiDB のパフォーマンステスト結果](/benchmark/v3.0-performance-benchmarking-with-sysbench.md) を参照してください。

TiKV アーキテクチャの Raft + 複数のレプリカを使用して絶対的なデータセーフティを達成できますか？スタンドアロンストレージに最も厳格なモード（`sync-log = true`）を適用する必要がありますか？
データは、ノードの障害が発生した場合に回復性を確保するために、TiKVノード間で冗長なレプリケーションが[Raft Consensus Algorithm](https://raft.github.io/)を使用して行われます。データがレプリカの50%以上に書き込まれてから、アプリケーションがACK（3つのノードのうち2つ）を返します。しかし理論上、2つのノードがクラッシュする可能性があります。そのため、データの安全性はあまり厳しくなく、パフォーマンスに極端な要件がある場合を除き、`sync-log`モードを有効にすることを強くお勧めします。

`sync-log`の代替手段として、Raftグループで3つの代わりに5つのレプリカを持つことも検討できます。これにより、2つのレプリカの故障に対応し、データの安全性を確保できます。

スタンドアロンのTiKVノードの場合、`sync-log`モードを有効にすることを強くお勧めします。それ以外の場合、ノードの障害時に最後の書き込みが失われる可能性があります。

### TiKVはRaftプロトコルを使用しているため、データ書き込み中に複数のネットワークラウンドトリップが発生します。実際の書き込みの遅延はどのくらいですか？

理論的には、TiDBの書き込み遅延はスタンドアロンのデータベースよりも4つの追加ネットワークラウンドトリップが発生します。

### TiDBには、InnoDB memcachedプラグイン（MySQLのようにKVインターフェースを直接使用し、独立したキャッシュを必要としない）がありますか？

TiKVはインタフェースを別々に呼び出すことができます。理論的には、インスタンスをキャッシュとして使用することができます。TiDBは分散リレーショナルデータベースであるため、TiKVを個別にサポートしていません。

### Coprocessorコンポーネントは何に使用されますか？

- TiDBとTiKV間のデータ送信を減らす
- TiKVの分散計算リソースを最大限に活用して計算プッシュダウンを実行する。

### `IOエラー: ファイルに空き領域がありません（ファイルへの追記時）`というエラーメッセージが表示されます

これはディスク容量が不足しているためです。ノードを追加したり、ディスク容量を拡張する必要があります。

### なぜTiKVでOOM（Out of Memory）エラーが頻繁に発生するのですか？

TiKVのメモリ使用量は、デフォルトでシステムメモリサイズの40%をブロックキャッシュのRocksDBから取得しています。TiKVでOOMエラーが頻繁に発生する場合は、`block-cache-size`の値が高すぎるかどうかを確認する必要があります。さらに、単一のマシンに複数のTiKVインスタンスを展開する場合は、複数のインスタンスがシステムメモリを過剰に使用してOOMエラーが発生することを防ぐために、明示的にパラメータを構成する必要があります。

### TiDBデータとRawKVデータを同じTiKVクラスタに保存できますか？

いいえ、TiDB（またはトランザクショナルAPIから作成されたデータ）は特定のキー形式に依存しています。これは他のRawKVベースのサービスから作成されたデータと互換性がないためです。

## TiDBテスト

このセクションでは、TiDBテスト中に遭遇する可能性がある一般的な問題、その原因、および解決策について説明します。

### Sysbenchを使用したTiDBのパフォーマンステスト結果はどうですか？

はじめに、多くのユーザーはTiDBとMySQLのベンチマークテストや比較テストを実施する傾向があります。私たちも同様の公式テストを実施し、その結果は一般的に一致しているとわかりましたが、テストデータにはわずかな偏りがあります。TiDBのアーキテクチャがMySQLと大きく異なるため、ベンチマークポイントを見つけることは難しいです。

- ベンチマークテストにあまり時間をかけないでください。TiDBを使用したシナリオの違いに注意を払ってください。
- [Sysbenchを使用したTiDBのパフォーマンステスト結果](/benchmark/v3.0-performance-benchmarking-with-sysbench.md)を参照してください。

### TiDBクラスタの容量（QPS）とノード数の関係は何ですか？TiDBはMySQLと比べてどのような性能ですか？

- 10ノード以内では、TiDBの書き込み容量（Insert TPS）とノード数の関係はおおよそ40%の線形増加です。MySQLは単一ノードの書き込みを使用しているため、その書き込み容量をスケールすることはできません。
- MySQLでは、読み込み容量はセカンダリデータベースを追加することで増やすことができますが、書き込み容量はシャーディングを使用しない限り増やすことはできません。シャーディングには多くの問題があります。
- TiDBでは、読み込み容量と書き込み容量の両方を簡単にノードを追加することで増やすことができます。

### DBAによるMySQLとTiDBのパフォーマンステストは、スタンドアロンのTiDBのパフォーマンスがMySQLほど良くないことを示しています

TiDBは、MySQLスタンドアロンの容量が限られている場合や強力な一貫性と完全な分散トランザクションが必要なシナリオに適して設計されています。TiDBの利点の1つは、計算をストレージノードにプッシュダウンして並列計算を実行することです。

TiDBは、小規模なデータ（数千万行未満）のテーブルには適していません。なぜなら、その強みである並列処理を小さなデータと制限されたRegionsでは示すことができないためです。典型的な例は、数行のレコードが頻繁に更新されるカウンターテーブルです。TiDBでは、これらの行はストレージエンジン内の複数のキーと値のペアになり、その後、TiKV上の単一ノードに存在する領域に収まります。強力な一貫性を保証するためのバックグラウンドレプリケーションのオーバーヘッドとTiDBからTiKVへの操作により、MySQLスタンドアロンよりもパフォーマンスが低下することがあります。

## バックアップとリストア

このセクションでは、バックアップとリストア中に遭遇する可能性がある一般的な問題、原因、および解決策について説明します。

### TiDBでデータをバックアップする方法は？

現在、大容量のデータ（1 TB以上）のバックアップには[バックアップ＆リストア（BR）](/br/backup-and-restore-overview.md)を使用することが推奨されています。それ以外の場合、推奨されるツールは[Dumpling](/dumpling-overview.md)です。公式のMySQLツールである`mysqldump`もTiDBでデータをバックアップおよびリストアするためにサポートされていますが、そのパフォーマンスはBRよりも優れておらず、大容量のデータをバックアップおよびリストアするためにはより多くの時間が必要です。

BRに関する詳細なFAQについては、[BR FAQs](/faq/backup-and-restore-faq.md)を参照してください。

### バックアップとリストアのスピードはどのくらいですか？

[BR](/br/backup-and-restore-overview.md)を使用してバックアップとリストアを実行する場合、バックアップはTiKVインスタンスごとに約40 MB/sで処理され、リストアはTiKVインスタンスごとに約100 MB/sで処理されます。