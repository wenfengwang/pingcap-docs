---
title: TiCDCのパフォーマンス分析とチューニングメソッド
summary: Performance Overview ダッシュボード上の TiCDC メトリクスを紹介し、TiCDC ワークロードをよりよく理解しモニタリングするのに役立ちます。
---

# TiCDCのパフォーマンス分析とチューニングメソッド

このドキュメントでは、TiCDCのリソース利用と主要なパフォーマンスメトリクスを紹介します。[CDCパネル](/grafana-performance-overview-dashboard.md#cdc)を使用して、Performance Overview ダッシュボードでTiCDCのパフォーマンスを監視することができます。

## TiCDCクラスターのリソース利用

次の3つのメトリクスにより、TiCDCクラスターのリソース利用状況を素早く把握できます：

- CPU使用率：TiCDCノードごとのCPU使用率。
- メモリ使用率：TiCDCノードごとのメモリ使用率。
- Goroutine数：TiCDCノードごとのゴールーチン数。

## TiCDCデータレプリケーションの主要メトリクス

### TiCDC全体のメトリクス

次のメトリクスにより、TiCDCのデータレプリケーション全体の概要を把握できます：

- Changefeedチェックポイント遅延：上流と下流間のデータレプリケーションの進捗遅延を秒単位で測定します。

    TiCDCがデータを消費して下流に書き込む速度が上流のデータ変更に追いついている場合、このメトリクスは一貫して小さな遅延範囲内にとどまります。さもなければ、このメトリクスは継続的に増加します。

    このメトリクス（すなわち「Changefeedチェックポイント遅延」）が増加する場合、一般的な原因は以下の通りです：

    - システムリソースが不足している：TiCDCのCPU、メモリ、またはディスク容量が不十分な場合、データ処理が遅くなり、TiCDC changefeedのチェックポイントが長時間にわたって発生する可能性があります。
    - ネットワークの問題：TiCDCでネットワークの中断、遅延、または帯域幅が不十分な場合、データ転送速度に影響を及ぼし、TiCDC changefeedのチェックポイントが長時間にわたって発生する可能性があります。
    - 上流での高いQPS：TiCDCで処理するデータが過度に大きい場合、データ処理のタイムアウトが発生し、TiCDC changefeedのチェックポイントが増加する可能性があります。通常、単一のTiCDCノードでは最大QPS約60Kを処理できます。
    - データベースの問題：
        - 上流TiKVクラスターの「min resolved ts」と最新のPD TSOとのギャップが大きい。これは通常、上流の書き込みワークロードが過度に重い場合にTiKVがタイムリーに「resolved ts」を進めることができないことで発生します。
        - 下流データベースでの書き込み遅延が高いため、TiCDCがデータをタイムリーに下流にレプリケートできない。

- Changefeed resolved ts遅延：TiCDCノードの内部レプリケーション状態と上流との進捗遅延を秒単位で測定します。このメトリクスが高い場合、TiCDC PullerまたはSorterモジュールのデータ処理能力が不十分である可能性があります。またはネットワーク遅延やディスクの読み書き速度の遅延が発生している可能性があります。これらの場合、効率的かつ安定したTiCDCの動作を確保するために、TiCDCノードの数を増やしたり、ネットワーク構成を最適化したりする必要があります。
- Changefeedのステータス：changefeedのステータスの説明については、[Changefeed state transfer](/ticdc/ticdc-changefeed-overview.md)を参照してください。

例1: 単一のTiCDCノードの場合、上流QPSが高いことによる高いチェックポイント遅延

以下の図に示すように、上流 QPS が過度に高く、クラスターには単一のTiCDCノードしかない場合、TiCDCノードは過負荷となり、CPU使用率が高くなり、「Changefeedチェックポイント遅延」と「Changefeed resolved ts遅延」がともに増加し続けます。 changefeedのステータスは「0」から「1」に断続的に遷移し、changefeedはエラーが発生し続けます。この問題は、次の対処方法を試すことで解決できます：

- TiCDCノードを追加する：TiCDCクラスターを複数のノードにスケーリングアウトして処理能力を向上させる。
- TiCDCノードのリソースを最適化する：TiCDCノードのCPUおよびメモリ構成を増やしてパフォーマンスを向上させる。

![TiCDC overview](/media/performance/cdc/cdc-slow.png)

### データフローのスループットメトリクスと下流の待機時間

次のメトリクスにより、TiCDCのデータフローのスループットと下流の待機時間を把握できます：

- Puller出力イベント/秒：TiCDCノードのPullerモジュールがSorterモジュールに送信する行数。
- Sorter出力イベント/秒：TiCDCノードのSorterモジュールがMounterモジュールに送信する行数。
- Mounter出力イベント/秒：TiCDCノードのMounterモジュールがSinkモジュールに送信する行数。
- Table Sink出力イベント/秒：TiCDCノードのTable SorterモジュールがSinkモジュールに送信する行数。
- SinkV2 - Sinkフラッシュ行/秒：TiCDCノードのSinkモジュールが下流に送信する行数。
- トランザクションSink完全フラッシュ期間：TiCDCノードのMySQL Sinkによる下流トランザクションの平均待機時間およびp999待機時間。
- MQ Workerメッセージ送信期間パーセンタイル：下流がKafkaの場合、MQ workerによるメッセージ送信の待機時間。
- Kafka送信バイト数：MQ Workload で下流トランザクションの書き込みトラフィック。

例2: 下流データベースの書き込み速度がTiCDCのデータレプリケーションのパフォーマンスに与える影響

以下の図に示すように、上流と下流がともにTiDBクラスターである場合、TiCDCの「Puller出力イベント/秒」メトリックは上流データベースのQPSを示します。TiCDCの「トランザクションSink完全フラッシュ期間」メトリックは下流データベースの平均書き込み待機時間を示し、最初のワークロード中に高くなり、2番目のワークロード中に低くなります。

- 最初のワークロード中、下流TiDBクラスターのデータ書き込み速度が遅いため、TiCDCは上流 QPS よりも遅れてデータを消費し、「Changefeedチェックポイント遅延」が継続的に増加します。しかし、「Changefeed resolved ts遅延」は300ミリ秒以内に収まっており、レプリケーション遅延やスループットのボトルネックはPullerおよびSorterモジュールではなく、下流のSinkモジュールによるとされます。
- 2番目のワークロード中、下流TiDBクラスターのデータ書き込み速度が速いため、TiCDCは上流に完全に追いつく速度でデータをレプリケートし、「Changefeedチェックポイント遅延」と「Changefeed resolved ts遅延」は両方とも500ミリ秒以内にとどまり、これはTiCDCにとって比較的理想的なレプリケーション速度です。

![TiCDC overview](/media/performance/cdc/cdc-fast-1.png)

![data flow and txn latency](/media/performance/cdc/cdc-fast-2.png)