---
title: TiDBの高いディスクI/O使用量のトラブルシューティング
summary: TiDBストレージの高いI/O使用量の問題を特定および解決する方法について学びます。
---

# TiDBの高いディスクI/O使用量のトラブルシューティング

この文書では、TiDBの高いディスクI/O使用量の問題を特定および解決する方法について紹介します。

## 現在のI/Oメトリクスを確認する

TiDBの応答が遅くなった場合、CPUのボトルネックおよびトランザクションの競合によるボトルネックをトラブルシューティングした後は、現在のシステムのボトルネックを特定するためにI/Oメトリクスを確認する必要があります。

### モニターからI/Oの問題を特定する

I/Oの問題を素早く特定する方法は、Grafanaのダッシュボードなどのモニターから全体的なI/Oの状態を表示することです。デフォルトでTiUPによって展開されるGrafanaダッシュボードでは、I/Oに関連する**概要**、**Node_exporter**、および**Disk-Performance**のパネルが含まれます。

#### 最初のタイプの監視パネル

**概要** > **システム情報** > **IO Util**では、クラスタ内の各マシンのI/Oの状態を確認できます。このメトリックは、Linuxの`iostat`モニターの`util`と類似しています。より高いパーセンテージはより高いディスクI/Oの使用量を表します。

- モニターにおいて高いI/O使用量のマシンが1台だけの場合は、現在そのマシンに読み書きのホットスポットがある可能性があります。
- モニターにおいてほとんどのマシンのI/O使用量が高い場合、クラスタには現在高いI/O負荷がかかっています。

上記の最初の状況（高いI/O使用量のマシンが1台だけの場合）については、**Disk-Performance Dashboard**などのI/Oメトリクスをさらに観察し、異常が存在するかどうかを判断するために`Disk Latency`および`Disk Load`などのメトリクスを確認できます。必要に応じて、ディスクの状態を確認するためにfioツールを使用します。

#### 2番目のタイプの監視パネル

TiDBクラスタの主要なストレージコンポーネントはTiKVです。1つのTiKVインスタンスには2つのRocksDBインスタンスが含まれており、1つはRaftログを保存するためのもので、`data/raft`に位置し、もう1つは実際のデータを保存するためのもので、`data/db`に位置します。

**TiKV-Details** > **Raft IO**では、これら2つのインスタンスのディスク書き込みに関連するメトリクスを確認できます。

- `Append log duration`：これはRaftログを保存するRockDBへの書き込みの応答時間を示します。`.99`の応答時間は50ミリ秒以内であるべきです。
- `Apply log duration`：これは実際のデータを保存するRockDBへの書き込みの応答時間を示します。`.99`の応答は100ミリ秒以内であるべきです。

これら2つのメトリクスには**.. per server**の監視パネルも含まれており、書き込みのホットスポットを表示するのに役立ちます。

#### 3番目のタイプの監視パネル

**TiKV-Details** > **Storage**にはストレージに関連する監視メトリクスが含まれています。

- `Storage command total`：受信した異なるコマンドの数を示します。
- `Storage async write duration`：`disk sync duration`などのモニタリングメトリクスが含まれており、これはRaft I/Oに関連するかもしれません。異常な状況に遭遇した場合はログを確認して関連するコンポーネントの作業状況を確認します。

#### その他のパネル

また、その他のパネルメトリクスもI/Oのボトルネックかどうかを判断するのに役立ち、いくつかのパラメータを設定してみることができます。TiKV gRPCのprewrite/commit/raw-put（ローカルキー値クラスターの場合）を確認することで、遅いTiKV書き込みのボトルネックかどうかを特定できます。遅いTiKV書き込みの一般的な状況は次のとおりです。

- `append log`が遅い。TiKV Grafanaの`Raft I/O`および`append log duration`メトリクスが比較的高い場合、これは通常ディスク書き込みが遅いためです。`RocksDB-raft`での`WAL Sync Duration max`の値を確認して`append log`の遅延の原因を特定します。それ以外の場合は、バグを報告する必要がある場合があります。
- `raftstore`スレッドがビジーです。TiKV Grafanaでは、`Raft Propose`／`propose wait duration`が`append log duration`よりもかなり高い場合があります。トラブルシューティングのために以下の点を確認します。
    - `[raftstore]`の`store-pool-size`の値が小さすぎるかどうかを確認します。この値は`[1,5]`の間に設定することをお勧めし、あまり大きくしすぎないようにします。
    - マシンのCPUリソースが不足していないかどうかを確認します。
- `append log`が遅い。TiKV Grafanaの`Raft I/O`および`append log duration`メトリクスが比較的高い場合、これは通常比較的高い`Raft Propose`／`apply wait duration`と一緒に発生します。以下のような可能な原因があります。
    - `[raftstore]`の`apply-pool-size`の値が小さすぎるかどうかを確認します。この値は`[1, 5]`の間に設定することをお勧めし、あまり大きくしすぎないようにします。`Thread CPU`／`apply cpu`の値も比較的高いです。
    - マシンのCPUリソースが不足していないかどうかを確認します。
    - 単一リージョンの書き込みホットスポットの問題（この問題の解決策はまだ途中です）。単一の`apply`スレッドのCPU使用率が高い（`by (instance, name)`で変更したGrafana expressionで表示できます）。
    - RocksDBへの書き込みが遅い場合、`RocksDB kv`／`max write duration`が高い場合もあります。1つのRaftログには複数のキー値ペア（kv）が含まれる場合があります。128個のkvが一括でRocksDBに書き込まれるため、1つの`apply`ログには複数のRocksDBの書き込みが含まれる場合があります。
    - その他の原因については、バグとして報告します。
- `raft commit log`が遅い。TiKV Grafanaの`Raft I/O`および`commit log duration`（Grafana 4.xでのみ利用可能）メトリクスが比較的高い場合があります。各リージョンには独立したRaftグループが対応しています。RaftにはTCPのスライディングウィンドウメカニズムに類似したフローコントロールメカニズムがあります。スライディングウィンドウのサイズを制御するには、`[raftstore] raft-max-inflight-msgs`のパラメータを調整します。書き込みホットスポットがある場合や`commit log duration`が高い場合は、このパラメータをより大きな値（たとえば`1024`）に適切に設定できます。

### ログからI/Oの問題を特定する

- クライアントで`server is busy`と報告されたエラーや特に`raftstore is busy`と報告されたエラーがある場合、これらのエラーはI/Oの問題と関連している可能性があります。

    `busy`エラーの具体的な原因を確認するためにモニタリングパネル（**Grafana** -> **TiKV** -> **errors**）を確認します。`server is busy`はTiKVのフローコントロールメカニズムです。この方法でTiKVは`tidb/ti-client`に対して、TiKVの現在の圧力が高すぎることを知らせ、クライアントは後で再試行するようにすることがあります。

- TiKV RocksDBのログに`Write stall`が表示されます。

    レベル-0のSSTファイルが多すぎて書き込みが停止している可能性があります。この問題を解決するために、`[rocksdb] max-sub-compactions = 2（または 3）`のパラメータを追加して、レベル-0からレベル-1へのコンパクションタスクを余剰スレッドで実行できるようにします。

    もしディスクのI/O能力が書き込みに追いついていない場合は、ディスクをスケーリングアップすることをお勧めします。ディスクのスループットが上限に達した場合（たとえば、SATA SSDのスループットはNVMe SSDのそれよりもはるかに低い場合）、これが書き込みの停滞を引き起こし、しかしCPUリソースが比較的十分な場合は、より高い圧縮率の圧縮アルゴリズムを使用することを試して、ディスクリソースの圧力を和らげることができます。つまり、CPUリソースを使ってディスクリソースを補うことです。

    たとえば、`default cf compaction`の圧力が比較的高い場合、`[rocksdb.defaultcf]`の`compression-per-level = ["no", "no", "lz4", "lz4", "lz4", "zstd" , "zstd"]`を`compression-per-level = ["no", "no", "zstd", "zstd", "zstd", "zstd", "zstd"]`に変更できます。

### アラートで見つかったI/Oの問題

クラスタの展開ツール（TiUP）はデフォルトでアラートコンポーネントを備え、組み込みのアラート項目と閾値を持っています。次のアラート項目はI/Oに関連しています。

- TiKV_write_stall
- TiKV_raft_log_lag
- TiKV_async_request_snapshot_duration_seconds
- TiKV_async_request_write_duration_seconds
- TiKV_raft_append_log_duration_secs
- TiKV_raft_apply_log_duration_secs

## I/Oの問題を処理する

+ I/Oホットスポットの問題が発生していることが確認された場合は、I/Oホットスポットを解消するために、I/O Hotspot Issuesの処理を参照してください。
+ 全体的なI/Oパフォーマンスがボトルネックになり、アプリケーション側でI/Oパフォーマンスが将来的にも追いつかないことが判明した場合は、分散データベースのスケーリング機能を利用してTiKVノードの数を増やし、より大きな全体的なI/Oスループットを実珸することができます。
+ 上記のようないくつかのパラメータを調整し、計算/メモリリソースを使用してディスクストレージリソースを補完してください。