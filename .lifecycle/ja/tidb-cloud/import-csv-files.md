---
title: Amazon S3またはGCSからCSVファイルをTiDB Cloudにインポートする
summary: Amazon S3またはGoogle Cloud Storage（GCS）からCSVファイルをTiDB Cloudにインポートする方法について学びます。
aliases: ['/tidbcloud/migrate-from-amazon-s3-or-gcs','/tidbcloud/migrate-from-aurora-bulk-import']
---

# Amazon S3またはGCSからCSVファイルをTiDB Cloudにインポートする

このドキュメントでは、Amazon Simple Storage Service（Amazon S3）またはGoogle Cloud Storage（GCS）からCSVファイルをTiDB Cloudにインポートする方法について説明します。

> **注：**
>
> - データの一貫性を確保するため、TiDB Cloudは空のテーブルにのみCSVファイルをインポートすることができます。すでにデータが含まれている既存のテーブルにデータをインポートするには、このドキュメントに従ってTiDB Cloudを使用して一時的な空のテーブルにデータをインポートし、その後`INSERT SELECT`ステートメントを使用してデータをターゲットの既存テーブルにコピーします。
> - TiDB Dedicatedクラスターにchangefeedがある場合、クラスターにデータをインポートできません（**Import Data**ボタンが無効になります）。「physical import mode」を使用するため、インポートされたデータは変更ログを生成せず、changefeedではインポートされたデータを検出できません。

## ステップ1. CSVファイルの準備

1. CSVファイルが256 MBより大きい場合は、256 MB程度のサイズの複数のファイルに分割することを検討してください。

    TiDB Cloudは非常に大きなCSVファイルのインポートをサポートしていますが、サイズが256 MB程度の複数の入力ファイルで最も効果的に動作します。これは、TiDB Cloudが複数のファイルを並列で処理できるため、インポート速度が大幅に向上することができるためです。

2. 次のようにCSVファイルに名前を付けます。

    - CSVファイルが表全体のすべてのデータを含む場合は、ファイルを`${db_name}.${table_name}.csv`形式で命名します。これにより、データをインポートするときに`${db_name}.${table_name}`テーブルにマップされます。
    - 1つのテーブルのデータが複数のCSVファイルに分割されている場合は、これらのCSVファイルに数値の接尾辞を付け加えます。例えば、`${db_name}.${table_name}.000001.csv`と`${db_name}.${table_name}.000002.csv`です。数値の接尾辞は連続していなければなりませんが、昇順である必要があります。また、すべての接尾辞が同じ長さになるようにするために数値の前に余分なゼロを追加する必要があります。
    - TiDB Cloudは次の形式の圧縮ファイルをインポートをサポートしています：`.gzip`、`.gz`、`.zstd`、`.zst`および`.snappy`。圧縮されたCSVファイルをインポートする場合は、ファイルを`${db_name}.${table_name}.${suffix}.csv.${compress}`形式で命名します。ここで`${suffix}`は任意で、`000001`などの整数にすることができます。たとえば、`trips.000001.csv.gz`ファイルを`bikeshare.trips`テーブルにインポートしたい場合は、ファイルを`bikeshare.trips.000001.csv.gz`として名前を変更する必要があります。

    > **注：**
    >
    > - データファイルのみを圧縮し、データベースまたはテーブルのスキーマファイルは圧縮しないでください。
    > - 性能を向上させるために、各圧縮ファイルのサイズを100 MiBに制限することをお勧めします。
    > - 圧縮されていないファイルの場合、いくつかの場合には（たとえば、CSVファイルリンクが他のプログラムでも使用されているため）、前述の規則に従ってCSVファイル名を更新できない場合は、ファイル名をそのままにして、[ステップ4](#step-4-import-csv-files-to-tidb-cloud)の**Mapping Settings**を使用してソースデータを単一のターゲットテーブルにインポートすることができます。

## ステップ2. ターゲットテーブルスキーマの作成

CSVファイルにはスキーマ情報が含まれていないため、CSVファイルからTiDB Cloudにデータをインポートする前に、次のいずれかの方法を使用してテーブルスキーマを作成する必要があります。

- 方法1：TiDB Cloudで、ソースデータのターゲットデータベースおよびテーブルを作成します。

- 方法2：Amazon S3またはGCSディレクトリでCSVファイルがある場合は、次のようにソースデータのターゲットテーブルスキーマファイルを作成します。

    1. ソースデータのためのデータベーススキーマファイルを作成します。

        CSVファイルが[ステップ1](#step-1-prepare-the-csv-files)で定義された命名規則に従っている場合、データベーススキーマファイルはインポートには任意です。そうでない場合は必須です。

        各データベーススキーマファイルは`${db_name}-schema-create.sql`形式である必要があり、`CREATE DATABASE` DDLステートメントを含んでいる必要があります。このファイルを使用すると、TiDB Cloudはデータのインポート時に`${db_name}`データベースを作成します。

        たとえば、次のステートメントを含む`mydb-scehma-create.sql`ファイルを作成すると、TiDB Cloudはデータのインポート時に`mydb`データベースを作成します。

        {{< copyable "sql" >}}

        ```sql
        CREATE DATABASE mydb;
        ```

    2. ソースデータのテーブルスキーマファイルを作成します。

        Amazon S3またはGCSディレクトリにテーブルスキーマファイルが含まれていない場合、TiDB Cloudはデータのインポート時に対応するテーブルを作成しません。

        各テーブルスキーマファイルは`${db_name}.${table_name}-schema.sql`形式である必要があり、`CREATE TABLE` DDLステートメントを含んでいる必要があります。このファイルを使用すると、TiDB Cloudはデータのインポート時に`${db_table}`データベース内に`${db_name}.${table_name}`テーブルを作成します。

        たとえば、次のステートメントを含む`mydb.mytable-schema.sql`ファイルを作成すると、TiDB Cloudはデータのインポート時に`mydb`データベース内に`mytable`テーブルを作成します。

        {{< copyable "sql" >}}

        ```sql
        CREATE TABLE mytable (
        ID INT,
        REGION VARCHAR(20),
        COUNT INT );
        ```

        > **注：**
        >
        > 各`${db_name}.${table_name}-schema.sql`ファイルには1つのDDLステートメントのみを含めるべきです。ファイルに複数のDDLステートメントが含まれている場合は、最初のステートメントのみが有効になります。

## ステップ3. クロスアカウントアクセスの構成

TiDB CloudがAmazon S3またはGCSバケット内のCSVファイルにアクセスできるようにするには、次のいずれかを行います。

- CSVファイルがAmazon S3にある場合は、[Amazon S3アクセスの構成](/tidb-cloud/config-s3-and-gcs-access.md#configure-amazon-s3-access)を行います。

    AWSアクセスキーまたはロールARNのいずれかを使用できます。完了したら、[ステップ4](#step-4-import-csv-files-to-tidb-cloud)で必要になるアクセスキー（アクセスキーIDとシークレットアクセスキーを含む）またはロールARNの値をメモします。

- CSVファイルがGCSにある場合は、[GCSアクセスの構成](/tidb-cloud/config-s3-and-gcs-access.md#configure-gcs-access)を行います。

## ステップ4. CSVファイルをTiDB Cloudにインポート

CSVファイルをTiDB Cloudにインポートするには、以下の手順を実行します。

1. ターゲットクラスターの**Import**ページを開きます。

    1. [TiDB Cloudコンソール](https://tidbcloud.com/)にログインし、プロジェクトの[**Clusters**](https://tidbcloud.com/console/clusters)ページに移動します。

        > **ヒント：**
        >
        > 複数のプロジェクトがある場合は、左下の<アイコン>をクリックして、別のプロジェクトに切り替えることができます。

    2. ターゲットクラスターの概要ページに移動し、左側のナビゲーションペインで**Import**をクリックします。

2. **Import**ページで：
   - TiDB Dedicatedクラスターの場合、右上隅にある**Import Data**をクリックします。
   - TiDB Serverlessクラスターの場合、アップロードエリアの上にある**S3からデータをインポート**リンクをクリックします。

3. ソースCSVファイルの以下の情報を提供します：

    - **ロケーション**: **Amazon S3**を選択します。
    - **データフォーマット**: **CSV**を選択します。CSV固有の構成を編集する必要がある場合は、**CSV構成の編集**をクリックしてCSV固有の構成を更新します。詳細については、[データのインポートのためのCSV設定](/tidb-cloud/csv-config-for-import-data.md)を参照してください。

        > **注：**
        >
        > セパレータとデリミタの構成について、英数字と特定の特殊文字を使用できます。サポートされている特殊文字には`\t`、`\b`、`\n`、`\r`、`\f`、および`\u0001`が含まれます。

    - **バケットURI**: CSVファイルが格納されているバケットURIを選択します。URIの末尾には`/`を含める必要があります。たとえば、`s3://sampledate/ingest/`のようにします。
    - **バケットアクセス**（AWS S3の場合のみ表示されるフィールド）：AWSアクセスキーまたはAWSロールARNのいずれかを使用できます。詳細については、[Amazon S3アクセスの構成](/tidb-cloud/config-s3-and-gcs-access.md#configure-amazon-s3-access)を参照してください。
        - **AWSアクセスキー**: AWSアクセスキーIDおよびAWSシークレットアクセスキーを入力します。
        - **AWSロールARN**: AWSロールARNの値を入力します。

4. **Pre-created Tablesにインポート**するか、**S3からスキーマとデータをインポート**するかを選択できます。
    - **事前作成されたテーブルにインポート**: これにより、TiDBに事前にテーブルを作成し、データをインポートしたいテーブルを選択することができます。この場合、最大1000のテーブルをインポートすることができます。テーブルを作成するには、左側のナビゲーションペインで**Chat2Qury**をクリックします。Chat2Queryの使用方法について詳しくは、[AIパワードのChat2Queryでデータを探索](/tidb-cloud/explore-data-with-chat2query.md)を参照してください。
    - **S3からスキーマとデータをインポート**: これにより、S3に保存されたテーブルとそれに対応するデータを直接TiDBに作成するSQLスクリプトをインポートすることができます。
    
5. ソースファイルが命名規則に準拠していない場合、各ターゲットテーブルとその対応するCSVファイルにカスタムマッピングルールを定義できます。その後、提供されたカスタムマッピングルールを使用してデータソースファイルを再スキャンします。マッピングを変更するには、**詳細設定**に移動し、**マッピング設定**をクリックします。**マッピング設定**は、**事前作成されたテーブルにインポート**を選択した場合にのみ利用可能です。

    - **ターゲットデータベース**: 選択したターゲットデータベースの名前を入力します。

    - **ターゲットテーブル**: 選択したターゲットテーブルの名前を入力します。このフィールドは特定のテーブル名のみを受け入れるため、ワイルドカードはサポートされていません。

    - **ソースファイルURIと名前**: ソースファイルのURIと名前を以下の形式で入力します `s3://[バケット名]/[データソースフォルダ]/[ファイル名].csv`。たとえば、`s3://sampledate/ingest/TableName.01.csv`です。ソースファイルにワイルドカードを使用することもできます。詳細については、[マッピング設定](#mapping-settings)を参照してください。

6. **インポートを開始**をクリックします。

7. インポートの進行状況が**完了**と表示されたら、インポートされたテーブルを確認します。

インポートタスクを実行する際に、サポートされていない変換や無効な変換が検出された場合、TiDB Cloudは自動的にインポートジョブを終了し、インポートエラーを報告します。

インポートエラーが発生した場合は、以下の手順を実行します。

1. 部分的にインポートされたテーブルを削除します。
2. テーブルスキーマファイルを確認します。エラーがある場合は、テーブルスキーマファイルを修正します。
3. CSVファイル内のデータ型を確認します。
4. インポートタスクをもう一度実行してください。

## マッピング設定

ソースファイルが命名規則に準拠していない場合、各ターゲットテーブルとその対応するCSVファイルにカスタムマッピングルールを定義できます。その後、提供されたカスタムマッピングルールを使用してデータソースファイルを再スキャンします。マッピングを変更するには、**詳細設定**に移動し、**マッピング設定**をクリックします。**マッピング設定**は、**事前作成されたテーブルにインポート**を選択した場合にのみ利用可能です。

**ソースファイルURIと名前**にソースファイルのURIと名前を入力する際には、次の形式 `s3://[バケット名]/[データソースフォルダ]/[ファイル名].csv`であることを確認してください。たとえば、`s3://sampledate/ingest/TableName.01.csv`です。

ソースファイルにワイルドカードを使用することもできます。たとえば:

- `s3://[バケット名]/[データソースフォルダ]/my-data?.csv`: そのフォルダ内の1文字を含む`my-data`で始まるすべてのCSVファイル（`my-data1.csv`や`my-data2.csv`など）が同じターゲットテーブルにインポートされます。

- `s3://[バケット名]/[データソースフォルダ]/my-data*.csv`: `my-data`で始まるフォルダ内のすべてのCSVファイルが同じターゲットテーブルにインポートされます。

**?** と **\*** だけがサポートされていることに注意してください。

> **注意:**
>
> URIにはデータソースフォルダを含める必要があります。

## トラブルシューティング

### データインポート中の警告の解決

**インポートを開始**をクリックした後、`対応するソースファイルが見つかりません`のような警告メッセージが表示された場合は、正しいソースファイルを提供し、既存のファイル名を[データインポートの命名規則](/tidb-cloud/naming-conventions-for-data-import.md)に従ってリネームするか、**詳細設定**を使用して変更を行います。

これらの問題を解決した後、再度データをインポートする必要があります。

### インポートされたテーブルの行数がゼロ

インポートの進行状況が**完了**と表示されたら、インポートされたテーブルを確認します。行数がゼロの場合、指定したバケットURIに一致するデータファイルが存在しないことを意味します。この場合は、正しいソースファイルを提供し、既存のファイル名を[データインポートの命名規則](/tidb-cloud/naming-conventions-for-data-import.md)に従ってリネームするか、**詳細設定**を使用して変更を行います。その後、これらのテーブルを再度インポートしてください。