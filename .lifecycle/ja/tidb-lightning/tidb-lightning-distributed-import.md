---
title: TiDB Lightningを使用してデータを並列でインポートする
summary: TiDB Lightningを使用してデータを並列でインポートする際の概念、ユーザーシナリオ、使用法、および制限について学びます。
---

# TiDB Lightningを使用してデータを並列でインポートする

TiDB Lightningの[物理的インポートモード](/tidb-lightning/tidb-lightning-physical-import-mode.md) はv5.3.0から単一のテーブルまたは複数のテーブルの並列インポートをサポートしています。複数のTiDB Lightningインスタンスを同時に実行することで、異なる単一テーブルまたは複数のテーブルからデータを並列にインポートすることが可能です。これにより、TiDB Lightningは水平方向に拡張する能力を提供し、大量のデータをインポートするために必要な時間を大幅に短縮します。

技術的実装では、TiDB Lightningは各インスタンスのメタデータやターゲットのTiDBにインポートされた各テーブルのデータを記録し、異なるインスタンスのRow ID割り当て範囲、グローバルChecksumの記録、およびTiKVとPDの構成変更と回復を調整します。

次のシナリオでTiDB Lightningを使用してデータを並列にインポートできます。

- シャーディングされたスキーマとシャーディングされたテーブルをインポート。このシナリオでは、複数の上流データベースインスタンスから複数のテーブルが、別々のTiDB Lightningインスタンスによって下流のTiDBデータベースに並列にインポートされます。
- 単一のテーブルを並列にインポート。このシナリオでは、特定のディレクトリやクラウドストレージ（Amazon S3など）に格納されている単一のテーブルが、別々のTiDB Lightningインスタンスによって下流のTiDBクラスタに並列にインポートされます。これはTiDB 5.3.0で導入された新機能です。

> **注意:**
>
> - 並列インポートはTiDBの初期化された空のテーブルのみをサポートし、既存のサービスによって書き込まれたデータを持つテーブルへのデータ移行はサポートしていません。そうでないと、データの不整合が発生する可能性があります。
>
> - 並列インポートは通常、物理的インポートモードで使用されます。`parallel-import = true`を設定する必要があります。
>
> - 同じターゲットに複数のTiDB Lightningインスタンスを使用してデータをインポートする際には、一度に1つのバックエンドのみを適用してください。例えば、同時に物理インポートモードと論理インポートモードで同じTiDBクラスタにデータをインポートすることはできません。

## 考慮事項

並列インポートを使用するためには、`parallel-import = true`を設定する必要があります。TiDB Lightningが起動すると、下流のTiDBクラスタにメタデータを登録し、自動的に同時にデータをターゲットクラスタに移行している他のインスタンスが存在するかどうかを検出します。存在する場合、自動的に並列インポートモードに入ります。

ただし、並列にデータを移行する際には、次のことに注意する必要があります。

- 複数のシャーディングされたテーブル間のプライマリキーまたは一意制約の競合を処理する
- インポートのパフォーマンスを最適化する

### 複数のシャーディングされたテーブル間のプライマリキーまたは一意制約の競合を処理する

物理的インポートモードを使用してデータを並列にインポートする際には、データソース間やターゲットのTiDBクラスタ内のプライマリキーや一意インデックスの競合がないことを確認し、インポート中にターゲットテーブルへのデータ書き込みがないことを確認してください。そうでないと、TiDB Lightningはインポートされたデータの正確性を保証できず、インポートが完了した後にターゲットテーブルに不整合なインデックスが含まれる可能性があります。

### インポートのパフォーマンスを最適化する

TiDB Lightningは生成されたKey-Valueデータを対応するRegionの各コピーが配置されているTiKVノードにアップロードする必要があるため、インポート速度はターゲットクラスタのサイズによって制限されます。以下の要件を満たすことで、最適なインポートパフォーマンスを達成できます。

- 各TiDB Lightningインスタンスを専用マシンに展開します。1つのTiDB LightningインスタンスはデフォルトですべてのCPUリソースを消費するため、複数のインスタンスを1台のマシンに展開してもパフォーマンスは向上しません。
- 並列インポートを実行する各TiDB Lightningインスタンスのソースファイルの合計サイズは5 TiB未満である必要があります。
- TiDB Lightningインスタンスの総数は10未満である必要があります。

TiDB Lightningを使用してデータベースとテーブルを並列でインポートする際には、データ量に応じて適切な数のTiDB Lightningインスタンスを選択してください。

- MySQLデータのボリュームが2 TiB未満の場合、1つのTiDB Lightningインスタンスを使用して並列インポートできます。
- MySQLデータのボリュームが2 TiBを超え、かつMySQLインスタンスの総数が10未満の場合、各MySQLインスタンスに1つのTiDB Lightningインスタンスを使用することをお勧めします。さらに、並列TiDB Lightningインスタンスの数は10を超えてはいけません。
- MySQLデータのボリュームが2 TiBを超え、かつMySQLインスタンスの総数が10を超える場合、これらのMySQLインスタンスによってエクスポートされたデータをインポートするために5から10のTiDB Lightningインスタンスを割り当てることをお勧めします。

次に、このドキュメントでは、2つの例を使用してさまざまなシナリオでの並列インポートの操作手順の詳細を説明します。

- 例1: Dumpling + TiDB Lightningを使用してTiDBにシャーディングされたデータベースとテーブルを並列にインポートする
- 例2: 単一のテーブルを並列にインポート

### 制限事項

TiDB Lightningは実行中に独自のリソースを排他的に使用します。1つのマシンに複数のTiDB Lightningインスタンスを展開する（本番環境ではお勧めできません）か、複数のマシンによって共有される1つのディスクに展開する必要がある場合は、次の使用制限に注意してください。

- `tikv-importer.sorted-kv-dir`をそれぞれのTiDB Lightningインスタンスに一意のパスに設定してください。同じパスを共有する複数のインスタンスは意図しない動作を引き起こし、インポートの失敗やデータのエラーを引き起こす可能性があります。
- 各TiDB Lightningのチェックポイントを別々に保存してください。チェックポイントの設定に関する詳細については、[TiDB Lightning Checkpoints](/tidb-lightning/tidb-lightning-checkpoints.md)を参照してください。
    - checkpoint.driver="file"（デフォルト）を設定する場合は、各インスタンスに一意のパスを設定してください。
    - checkpoint.driver="mysql"を設定する場合は、各インスタンスに一意のスキーマを設定する必要があります。
- 各TiDB Lightningのログファイルを一意のパスに設定してください。同じログファイルを共有すると、ログのクエリやトラブルシューティングに影響が出ます。
- [Web Interface](/tidb-lightning/tidb-lightning-web-interface.md)やDebug APIを使用する場合は、各インスタンスに対して`lightning.status-addr`を一意のアドレスに設定する必要があります。そうでないと、ポートの競合によりTiDB Lightningプロセスが起動に失敗します。

## 例1: Dumpling + TiDB Lightningを使用してTiDBにシャードされたデータベースとテーブルを並列にインポートする

この例では、上流が合計サイズが10 TiBの10個のシャードテーブルを持つMySQLクラスタで、5つのTiDB Lightningインスタンスを使用して並列インポートを実行します。各インスタンスは2 TiBをインポートし、インポート時間は合計40時間から10時間程度に短縮されると推定されます。

上流のライブラリ名は`my_db`であり、各シャーディングされたテーブルの名前は`my_table_01`から`my_table_10`です。これらを統合し、下流の`my_db.my_table`テーブルにインポートしたい場合、具体的な手順は以下のセクションで説明します。

### ステップ1: Dumplingを使用してデータをエクスポートする

TiDB Lightningが展開されている5つのノードで2つのシャーディングされたテーブルをエクスポートします。

- 2つのシャーディングされたテーブルが同じMySQLインスタンスにある場合は、Dumplingの`--filter`パラメータを使用して直接エクスポートできます。TiDB Lightningを使用してインポートする際には、`data-source-dir`をDumplingがデータをエクスポートするディレクトリとして指定できます。
- 2つのシャーディングされたテーブルのデータが異なるMySQLノードに分散されている場合は、Dumplingを使用してそれぞれを別々にエクスポートする必要があります。エクスポートされたデータは同じ親ディレクトリ内の異なるサブディレクトリに配置する必要があります。並列インポートを実行する際は、`data-source-dir`を親ディレクトリとして指定する必要があります。

Dumplingを使用してデータをエクスポートする方法の詳細については、[Dumpling](/dumpling-overview.md)を参照してください。

### ステップ2: TiDB Lightningデータソースを構成する

`tidb-lightning.toml`という構成ファイルを作成し、次のコンテンツを追加してください。

```
[lightning]
status-addr = ":8289"

[mydumper]
# Dumplingがデータをエクスポートするパスを指定します。Dumplingを複数回実行し、データが異なるディレクトリにある場合は、すべてのエクスポートされたデータを同じ親ディレクトリに配置し、ここで親ディレクトリを指定します。
data-source-dir = "/path/to/source-dir"

[tikv-importer]
# データが既にあるテーブルのインポートを許可するかどうか。デフォルト値は"false"です。
# 並列インポートを行う場合、複数のTiDB Lightningインスタンスが同時にテーブルをインポートするため、この構成項目を"true"に設定する必要があります。
parallel-import = true
# "local": デフォルトのモード。大規模なデータセットのインポートに適用されます（例：1 TiBを超える）。ただし、インポート中は下流のTiDBがサービスを提供できません。
# "tidb": 小規模なデータセットのインポートにこのモードを使用できます（例：1 TiB未満）。インポート中に下流のTiDBがサービスを提供できます。
backend = "local"

# ローカルソートデータのパスを指定します。
sorted-kv-dir = "/path/to/sorted-dir"
```

データソースがAmazon S3やGCSなどの外部ストレージに格納されている場合は、接続用の追加パラメータを構成する必要があります。詳細な設定例として、次の例ではデータがAmazon S3に格納されていると仮定します。

```
```
./tidb-lightning --tidbポート=4000 --pd-urls=127.0.0.1:2379 --バックエンド=ローカル --ソートされたkv-ディレクトリ=/tmp/sorted-kvs \
    -d 's3://my-bucket/sql-backup'
```

外部ストレージサービスのURIフォーマットについての詳細なパラメータ説明については、[URIフォーマット](/external-storage-uri.md)を参照してください。

### ステップ3：TiDB Lightningを起動してデータをインポート

並列インポート中、各TiDB Lightningノードのサーバー構成要件は非並列インポートモードと同じです。各TiDB Lightningノードは同じリソースを消費する必要があります。異なるサーバーに展開することをお勧めします。詳細な展開手順については、[TiDB Lightningの展開](/tidb-lightning/deploy-tidb-lightning.md)を参照してください。

順番に各サーバーでTiDB Lightningを起動します。コマンドラインから直接`nohup`を使用して開始すると、SIGHUPシグナルのために終了することがあります。そのため、例えば以下のようにスクリプトに`nohup`を入れることをお勧めします:

```shell
# !/bin/bash
nohup tiup tidb-lightning -config tidb-lightning.toml > nohup.out &
```

並列インポート中、TiDB Lightningはタスクを開始した後、自動的に以下のチェックを実行します。

- ローカルディスク（`sort-kv-dir`構成により制御）およびTiKVクラスターにインポートデータの十分なスペースがあるかどうかをチェックします。必要なディスクスペースについては、[下流ストレージスペースの要件](/tidb-lightning/tidb-lightning-requirements.md#storage-space-of-the-target-database)および[リソース要件](/tidb-lightning/tidb-lightning-physical-import-mode.md#environment-requirements)を参照してください。 TiDB Lightningはデータソースをサンプリングし、サンプル結果からインデックスサイズのパーセンテージを推定します。インデックスが推定に含まれているため、ソースデータのサイズがローカルディスクの利用可能なスペースよりも少ない場合でも、チェックに失敗することがあります。
- TiKVクラスター内のリージョンが均等に分散されており、空のリージョンがあまりにも多くないかどうかをチェックします。空のリージョンの数がmax(1000、テーブルの数 * 3)を超える場合、つまり空のリージョンの数が「1000」または「テーブル数の3倍」よりも多い場合、インポートを実行できません。
- データがデータソースから順にインポートされているかどうかをチェックします。 `mydumper.batch-size`のサイズは、チェック結果に基づいて自動的に調整されます。したがって、`mydumper.batch-size`構成はもはや使用できません。

さらに、`lightning.check-requirements`構成でチェックをオフにして、強制的にインポートを実行することもできます。より詳細なチェックについては、[TiDB Lightningの事前チェック](/tidb-lightning/tidb-lightning-prechecks.md)を参照してください。

### ステップ4: インポート進捗の確認

インポートを開始した後、次のいずれかの方法で進捗を確認できます。

- `grep`ログキーワード`progress`を介して進捗状況を確認します。デフォルトでは、5分ごとに更新されます。
- 監視コンソールを使用して進捗状況を確認します。詳細については、[TiDB Lightningモニタリング](/tidb-lightning/monitor-tidb-lightning.md)を参照してください。

すべてのTiDB Lightningインスタンスが完了するのを待ってから、インポート全体が完了します。

### 例2：単一の表を並列にインポート

TiDB Lightningは、単一の表の並列インポートもサポートしています。たとえば、Amazon S3に格納されている複数の単一の表を異なるTiDB Lightningインスタンスで並列に下流のTiDBクラスターにインポートする場合を考えてみましょう。この方法は、全体のインポート速度を高速化することができます。Amazon S3のようなリモートストレージを使用する場合、TiDB Lightningの構成パラメータはBRのそれと同じです。詳細については、[外部ストレージサービスのURIフォーマット](/external-storage-uri.md)を参照してください。

> **注意:**
>
>ローカル環境では、Dumplingの`--filesize`または`--where`パラメータを使用して、単一の表のデータを複数のサーバーのローカルディスクに事前に分割してエクスポートすることができます。これにより、並列でのインポートを行うことができます。この設定は例1と同じです。

ソースファイルがAmazon S3に格納されており、テーブルファイルが`my_db.my_table.00001.sql`〜`my_db.my_table.10000.sql`の合計10,000個のSQLファイルがあると仮定します。インポートを高速化するために2つのTiDB Lightningインスタンスを使用する場合、構成ファイルに以下の設定を追加する必要があります:

```
[[mydumper.files]]
# データベーススキーマファイル
pattern = '(?i)^(?:[^/]*/)*my_db-schema-create\.sql'
schema = "my_db"
type = "schema-schema"

[[mydumper.files]]
# テーブルスキーマファイル
pattern = '(?i)^(?:[^/]*/)*my_db\.my_table-schema\.sql'
schema = "my_db"
table = "my_table"
type = "table-schema"

[[mydumper.files]]
# 00001~05000のみをインポートし、他のファイルは無視します
pattern = '(?i)^(?:[^/]*/)*my_db\.my_table\.(0[0-4][0-9][0-9][0-9]|05000)\.sql'
schema = "my_db"
table = "my_table"
type = "sql"

[tikv-importer]
# 既にデータを持つテーブルにデータをインポートすることを許可するかどうか。デフォルト値は `false` です。
# 並列インポートを使用する場合、複数のTiDB Lightningインスタンスが同時にテーブルをインポートするため、この構成項目を `true` に設定する必要があります。
parallel-import = true
```

もう一方のインスタンスの構成を変更して、`05001 ~ 10000` のデータファイルのみをインポートするようにすることができます。

その他のステップについては、例1の関連する手順をご覧ください。

## エラーの処理

### TiDB Lightningノードのいくつかが異常終了します

並列インポート中に1つ以上のTiDB Lightningノードが異常終了した場合、記録されたエラーに基づいて原因を特定し、エラーの種類に応じて処理を行います。

- エラーが正常な終了（たとえば、killコマンドに応答して終了する）またはOOMによるオペレーティングシステムによる終了を示す場合、構成を調整してからTiDB Lightningノードを再起動します。

- エラーがデータの正確性に影響を与えない場合（たとえば、ネットワークのタイムアウト）、次の手順を実行します:

    1. 失敗したすべてのノードで [`checkpoint-error-ignore`](/tidb-lightning/tidb-lightning-checkpoints.md#--checkpoint-error-ignore) コマンドを「`--checkpoint-error-ignore=all` 」と設定して実行し、チェックポイントソースデータのエラーをクリーニングします。

    2. これらのノードを再起動して、チェックポイントからのデータインポートを継続します。

- ソースファイルの無効データを示すチェックサム不一致など、データの不正確性につながるエラーがログに表示されている場合、次の手順を実行してこの問題を解決できます:

    1. 成功したノードを含むすべてのLightningノードで[`checkpoint-error-destroy`](/tidb-lightning/tidb-lightning-checkpoints.md#--checkpoint-error-destroy)コマンドを実行します。このコマンドは、失敗したテーブルからインポートされたデータを削除し、これらのテーブルのチェックポイントの状態を「まだ開始していない」にリセットします。

    2. [`filter`](/table-filter.md)パラメータを使用して、正常に終了したノードを含むすべてのTiDB Lightningノードで、失敗したテーブルのデータの再設定とインポートを行います。

    Lightning並列インポートタスクを再設定する際は、各Lightningノードの起動スクリプトに`checkpoint-error-destroy`コマンドを含めないでください。そうしないと、複数の並列インポートタスクで使用される共有メタデータが削除され、データインポート中に問題が発生する可能性があります。たとえば、2番目のLightningインポートタスクを開始した場合、最初のタスクによって書き込まれたメタデータが削除され、データインポートが異常になる可能性があります。

### インポート中に「ターゲット・テーブルはチェックサムを計算しています。チェックサムが終わるまでお待ちいただき、再度お試しください」というエラーが報告されます

一部の並列インポートでは多くのテーブルが含まれるか、データのボリュームが小さなテーブルが含まれることがあります。この場合、1つ以上のタスクがテーブルの処理を開始する前に、このテーブルの他のタスクが終了し、データのチェックサムが進行中である可能性があります。この時、「Target table is calculating checksum. Please wait until the checksum is finished and try again」というエラーが報告されます。この場合、チェックサムの完了を待ってから失敗したタスクを再起動することができます。エラーは消え、データの正確性には影響しません。