---
title: パフォーマンス分析とチューニング
summary: データベースの時間に基づいたチューニング方法を学び、TiDB パフォーマンス概要ダッシュボードを使用してパフォーマンス分析とチューニングを行う方法について説明します。
---

# パフォーマンス分析とチューニング

このドキュメントでは、データベースの時間に基づいたチューニング手法を説明し、パフォーマンス分析とチューニングのために TiDB [パフォーマンス概要ダッシュボード](/grafana-performance-overview-dashboard.md)を使用する方法を示します。

このドキュメントで説明する方法を使用すると、ユーザーの応答時間とデータベースの時間をグローバルかつトップダウンの視点から分析し、ユーザーの応答時間のボトルネックがデータベースの問題によるものであるかどうかを確認できます。データベースがボトルネックである場合、データベースの時間の概要と SQL のレイテンシの解析により、ボトルネックを特定し、パフォーマンスをチューニングすることができます。

## データベースの時間に基づいたパフォーマンスチューニング

TiDB は SQL 処理のパスとデータベースの時間を定期的に計測・収集しているため、TiDB におけるデータベースのパフォーマンスボトルネックを容易に特定できます。データベースの時間のメトリクスに基づいて、次の 2 つの目標を達成できます。

- 平均 SQL 処理待ち時間と TiDB コネクション内のアイドル時間を比較することで、ボトルネックが TiDB にあるかどうかを判断できます。
- ボトルネックが TiDB にある場合、データベースの時間の概要と SQL のレイテンシの解析により、分散システム内の正確なモジュールを特定し、パフォーマンスをチューニングできます。

### TiDB がボトルネックであるかどうか

- トランザクションの TiDB コネクション内の平均アイドル時間が平均 SQL 処理待ち時間よりも長い場合、データベースはアプリケーションのトランザクションレイテンシの原因ではありません。データベースの時間はユーザーの応答時間の一部でしかありませんので、ボトルネックはデータベースの外側にあることを示しています。

    この場合、データベースの外部コンポーネントをチェックしてください。たとえば、アプリケーションサーバーのハードウェアリソースが十分であるかどうか、アプリケーションからデータベースへのネットワークレイテンシが過度に高いかどうかを確認してください。

- 平均 SQL 処理待ち時間がトランザクションの TiDB コネクション内の平均アイドル時間よりも長い場合、トランザクションのボトルネックは TiDB にあり、データベースの時間がユーザーの応答時間の大部分を占めます。

### ボトルネックが TiDB にある場合、どのように特定しますか？

次の図は典型的な SQL 処理を示しています。ほとんどの SQL 処理パスが TiDB のパフォーマンスメトリクスでカバーされていることがわかります。データベースの時間は異なる次元に分解され、それに応じて色分けされています。もしボトルネックがあれば、データベース内でそれを素早く特定し、ワークロード特性を理解することができます。

![データベースの時間の分解図](/media/performance/dashboard-diagnostics-time-relation.png)

データベースの時間は、すべての SQL 処理時間の合計です。データベースの時間を以下の 3 つの次元に分解することで、TiDB のボトルネックを迅速に特定できます。

- SQL の処理タイプ別: データベースの時間が最も多く消費される SQL ステートメントのタイプを判断します。計算式は次の通りです。

    `DB Time = Select Time + Insert Time + Update Time + Delete Time + Commit Time + ...`

- SQL の処理 4 ステップ (get_token/parse/compile/execute) 別: 最も多くの時間が消費されているステップを特定します。計算式は次の通りです。

    `DB Time = Get Token Time + Parse Time + Compile Time + Execute Time`

- 実行時間、TSO 待ち時間、KV リクエスト時間、および実行リトライ時間別: ボトルネックを構成している実行ステップを特定します。計算式は次の通りです。

    `Execute Time ~= TiDB Executor Time + KV Request Time + PD TSO Wait Time + Retried execution time`

## パフォーマンス分析とパフォーマンスチューニングにパフォーマンス概要ダッシュボードを使用する

このセクションでは、Grafana のパフォーマンス概要ダッシュボードを使用して、データベースの時間に基づいたパフォーマンス分析とチューニングを行う方法について説明します。

パフォーマンス概要ダッシュボードは、TiDB、PD、TiKV のメトリクスを組み合わせ、以下のセクションでそれぞれの情報を表示します。

- データベースの時間と SQL 実行時間の概要: 色で表示された SQL の種類、SQL 実行フェーズごとのデータベースの時間、および異なるリクエストのデータベースの時間を用いて、データベースのワークロード特性とパフォーマンスボトルネックを迅速に特定できます。
- 主要なメトリクスとリソース利用: データベースの QPS、コネクション情報、アプリケーションとデータベース間のリクエストコマンドの種類、データベース内部の TSO と KV リクエスト OPS、および TiDB/TiKV のリソース利用状況が含まれています。
- トップダウンのレイテンシブレークダウン: クエリのレイテンシとコネクションのアイドル時間の比較、クエリレイテンシの分解、SQL 実行中の TSO リクエストと KV リクエストのレイテンシ、および TiKV の内部書き込みレイテンシの分解が含まれています。

### データベースの時間と SQL 実行時間の概要

データベースの時間メトリクスは、TiDB が 1 秒あたりに処理する SQL の遅延の合計であり、また、TiDB が 1 秒あたりにアプリケーションの SQL リクエストを並行して処理する総時間です（アクティブなコネクション数と同じです）。

パフォーマンス概要ダッシュボードでは、次の 3 つのスタックエリアグラフが提供されています。これらは、ステートメント、SQL フェーズ、および SQL 実行中の TiKV または PD リクエストタイプに関して、ボトルネックの原因を素早く特定するのに役立ちます。

- SQL タイプ別のデータベースの時間
- SQL フェーズ別のデータベースの時間
- SQL 実行時間の概要

#### 色によるチューニング

データベースの時間の分解図と実行時間の概要図は、予想される時間消費と予期しない時間消費の両方を直感的に示しています。そのため、パフォーマンスのボトルネックを迅速に特定し、ワークロードの特性を把握することができます。緑と青の領域は正常な時間消費とリクエストを表しています。もし、これらの図の非緑または非青の領域が大部分を占めている場合、データベースの時間の分布が適切ではないことを意味します。

- SQL タイプ別のデータベースの時間:

    - 青: `SELECT` ステートメント
    - 緑: `UPDATE`、`INSERT`、`COMMIT` などの DML ステートメント
    - 赤: `StmtPrepare`、`StmtReset`、`StmtFetch`、`StmtClose` を含む一般的な SQL タイプ

- SQL フェーズ別のデータベースの時間: SQL の実行フェーズは緑色で、その他のフェーズは赤色です。もし、非緑色の領域が大きい場合、実行フェーズ以外のフェーズで多くのデータベースの時間が消費されていることを意味し、さらなる原因分析が必要です。一般的なシナリオは、オレンジ色で表示されるコンパイルフェーズがプリペアドプランキャッシュが利用できないために大きな領域を占めていることです。
- SQL 実行時間の概要: 緑のメトリクスは一般的な KV 書き込みリクエスト（`Prewrite` および `Commit` など）、青のメトリクスは一般的な KV 読み取りリクエスト（Cop および Get など）、紫のメトリクスは TiFlash MPP リクエストを表し、その他の色のメトリクスは注目が必要な予期しない状況を示しています。たとえば、悲観的なロックの KV リクエストは赤く、TSO の待ち時間はダークブラウンで表示されます。非青色または非緑色の領域が大きい場合、SQL の実行中にボトルネックが発生していることを意味します。たとえば:

    - 深刻なロックの競合が発生する場合、赤い領域が大部分を占めます。
    - TSO の待ち時間が過度にかかる場合、ダークブラウンの領域が大部分を占めます。

**例 1: TPC-C ワークロード**

![TPC-C](/media/performance/tpcc_db_time.png)

- SQL タイプ別のデータベースの時間: 最も時間のかかるステートメントは、`commit`、`update`、`select`、`insert` ステートメントです。
- SQL フェーズ別のデータベースの時間: 最も時間のかかるフェーズは緑色の SQL 実行フェーズです。
- SQL 実行時間の概要: SQL の実行中における最も時間のかかる KV リクエストは、緑色の `Prewrite` と `Commit` です。

    > **注釈:**
    >
    > KV リクエストの合計時間が実行時間よりも長いのは正常です。TiDB のエグゼキュータは複数の TiKV に同時に KV リクエストを送信するため、合計 KV リクエスト待ち時間は実行時間よりも長くなることがあります。前述の TPC-C のワークロードでは、トランザクションがコミットされる際に、TiDB は複数の TiKV に同時に `Prewrite` と `Commit` のリクエストを送信します。したがって、この例では `Prewrite`、`Commit`、および `PessimisticsLock` のリクエストの合計時間が実行時間よりも明らかに長くなります。
    >
    > - `execute` の時間が、KV リクエストの合計時間と `tso_wait` の時間の合計よりもかなり長い場合、それは SQL の実行時間の大部分が TiDB エグゼキュータの内部で費やされていることを意味します。以下に 2 つの一般的な例を示します:
    >
        > - 例 1: TiDB エグゼキュータが TiKV から大量のデータを読み込んだ後、TiDB 内で複雑な結合や集計を行う必要があるため、多くの時間がかかります。
        > - 例 2: アプリケーションで深刻な書き込みステートメントのロック競合が発生しています。頻繁なロックの再試行により、`Retried execution time` が長くなります。

**例 2: OLTP リードヘビーワークロード**

![OLTP](/media/performance/oltp_normal_db_time.png)

- SQL タイプ別のデータベースの時間: 最も時間のかかるステートメントは、`SELECT`、`COMMIT`、`UPDATE`、`INSERT` ですが、そのうち `SELECT` が最も多くのデータベースの時間を消費しています。
- SQL フェーズ別のデータベースの時間: 緑色の SQL 実行フェーズで最も多くの時間が消費されています。
- SQL 実行時間の概要: SQL の実行フェーズで、ダークブラウンの `pd tso_wait`、青色の `KV Get`、および緑色の `Prewrite` と `Commit` の時間が消費されます。

**例 3: OLTP の読み取り専用ワークロード**

![OLTP](/media/performance/oltp_long_compile_db_time.png)

- SQL タイプ別のデータベースの時間: 主に `SELECT` ステートメントです。
- SQL フェーズ別のデータベースの時間: オレンジ色のコンパイルフェーズと緑色の実行フェーズが最も多くの時間を消費しています。コンパイルフェーズのレイテンシが最も高いため、TiDB の実行計画の生成に時間がかかっており、その原因は後続のパフォーマンスデータに基づいてさらに特定する必要があります。
- SQL 実行時間の概要: SQL の実行中で最も長い時間がかかるのは、青色の KV BatchGet リクエストです。

> **注釈:**
>
> 例3では、 `SELECT` ステートメントは複数のTiKVから同時に数千行を読み取る必要があります。したがって、 `BatchGet`リクエストの合計時間は実行時間よりもはるかに長くなります。

**例4：ロック競合のワークロード**

![OLTP](/media/performance/oltp_lock_contention_db_time.png)

- SQLタイプごとのデータベース時間：主に `UPDATE` ステートメントです。
- SQLフェーズごとのデータベース時間：ほとんどの時間は、緑色の実行フェーズで消費されます。
- SQL実行時間の概要：SQL実行中に最も時間を消費するのは、赤色で表示される `PessimisticLock` リクエストで、実行時間はKVリクエストの合計時間よりも明らかに長くなります。これは、書き込みステートメントのロック競合が深刻であり、頻繁なロックの再試行により `Retried execution time` が延長されるためです。現時点では、TiDBは `Retried execution time` を測定していません。

**例5：HTAP CH-Benchmarkワークロード**

![HTAP](/media/performance/htap_tiflash_mpp.png)

- SQLタイプごとのデータベース時間：主に `SELECT` ステートメントです。
- SQLフェーズごとのデータベース時間：ほとんどの時間は、緑色の実行フェーズで消費されます。
- SQL実行時間の概要：紫色で表示される `tiflash_mpp` リクエストがSQL実行中に最も時間を消費し、次に青色の `Cop` リクエスト、緑色の `Prewrite` リクエスト、 `Commit` リクエストが続きます。

### TiDBの主なメトリクスとクラスタのリソース利用率

#### Query Per Second、Command Per Second、およびPrepared-Plan-Cache
性能概要の次の3つのパネルをチェックすることで、アプリケーションのワークロードタイプ、アプリケーションがTiDBとやり取りする方法、およびアプリケーションがTiDBの [準備プランキャッシュ](/sql-prepared-plan-cache.md) を完全に使用しているかを学ぶことができます。

- QPS：Query Per Secondの省略形。これにより、アプリケーションによって実行されたSQLステートメントの数が表示されます。
- タイプ別CPS：Command Per Secondの省略形。コマンドはMySQLプロトコル固有のコマンドを指します。クエリステートメントは、クエリコマンドまたはプリペアドステートメントのいずれかでTiDBに送信できます。
- Prepared Plan Cache OPSでのクエリの使用：`avg-hit` は、TiDBクラスタで実行されるクエリの実行計画キャッシュを毎秒使用する回数を示し、`avg-miss` は、実行計画キャッシュを使用しないクエリの数をTiDBクラスタで毎秒示します。

    `avg-hit + avg-miss` は `StmtExecute` に等しく、これは秒間に実行されるすべてのクエリの数です。TiDBで準備プランキャッシュが有効になっている場合、次の3つのシナリオが発生します。

    - 準備プランキャッシュがヒットしない場合： `avg-hit` （秒間のヒット数）が0であり、 `avg-miss` は `StmtExecute` コマンドの数に等しいです。可能な理由は次のとおりです。
        - アプリケーションはクエリインターフェースを使用しています。
        - アプリケーションが `StmtExecute` 実行後に `StmtClose` コマンドを呼び出し、キャッシュされたプランがクリアされました。
        - `StmtExecute` によって実行されるすべてのステートメントが [キャッシュ条件](/sql-prepared-plan-cache.md) を満たさないため、実行計画キャッシュがヒットしません。

    - すべての準備プランキャッシュがヒットする場合： `avg-hit` （秒間のヒット数）が `StmtExecute` コマンドの数に等しく、 `avg-miss` （ヒットしない数）が0です。
    - 一部の準備プランキャッシュがヒットする場合： `avg-hit` （秒間のヒット数）が `StmtExecute` コマンドの数よりも少ないです。準備プランキャッシュには既知の制限事項があります。例えば、サブクエリをサポートしていないため、サブクエリを含むSQLステートメントは準備プランキャッシュを使用することができません。

**例1：TPC-Cワークロード**

TPC-Cワークロードでは、主に `UPDATE`、 `SELECT`、および `INSERT` ステートメントがあります。合計のQPSは、毎秒の `StmtExecute` コマンド数とほぼ `Queries Using Plan Cache OPS` パネルの `avg-hit` に等しいです。理想的には、クライアントがプリペアドステートメントのオブジェクトをキャッシュします。この方法で、キャッシュされたステートメントは実行されるたびに直接呼び出されます。すべてのSQL実行は準備されたプランキャッシュにヒットし、実行計画を再コンパイルして生成する必要はありません。

![TPC-C](/media/performance/tpcc_qps.png)

**例2：読み取り専用OLTPワークロードのクエリコマンドに対する準備プランキャッシュが利用できない**

このワークロードでは、 `Commit QPS` = `Rollback QPS` = `Select QPS` です。アプリケーションは自動コミット並行性を有効にしており、ロールバックは接続プールから接続が取得されるたびに実行されます。そのため、これらの3つのステートメントは同じ回数実行されます。

![OLTP-Query](/media/performance/oltp_long_compile_qps.png)

- QPSパネルの赤い太字のラインは失敗したクエリの数を示し、右のY軸には失敗したクエリの座標値が表示されます。0以外の値は失敗したクエリが存在することを意味します。
- 合計のQPSは、CPS By Typeパネルのクエリの数に等しく、クエリコマンドはアプリケーションで使用されています。
- `Queries Using Plan Cache OPS` パネルにデータがないため、クエリコマンドに対して準備プランキャッシュが利用できません。これは、TiDBが各クエリ実行の解析と実行計画の生成を行う必要があることを意味し、結果としてTiDBのCPU消費が増加し、コンパイル時間が長くなります。

**例3：OLTPワークロードでの検索ステートメント有効な準備ステートメントの準備プランキャッシュが利用できない**

`StmtPreare` 回数 = `StmtExecute` 回数 = `StmtClose` 回数 ≈ `StmtFetch` 回数。アプリケーションは、準備 -> 実行 -> フェッチ -> クローズのループを使用しています。準備されたステートメントオブジェクトのリークを防ぐために、多くのアプリケーションフレームワークが `execute` の後に `close` を呼び出します。これには2つの問題があります。

- SQLの実行には4つのコマンドと4つのネットワークラウンドトリップが必要です。
- `Queries Using Plan Cache OPS` パネルで、`avg-miss` は、CPS By Typeパネルの `StmtExecute` とほぼ等しいです。これは、ほとんどすべてのSQL実行が実行計画キャッシュをミスしていることを示しています。

> **注意:**
>
> TiDB v6.0.0から、グローバル変数（`set global tidb_ignore_prepared_cache_close_stmt=on;`）を介して、 `StmtClose` コマンドがキャッシュされた実行計画をクリアしないようにすることができます。これにより、後続の実行は準備プランキャッシュをヒットすることができます。

![OLTP-Prepared](/media/performance/oltp_prepared_statement_no_plan_cache.png)

**例4：準備ステートメントにはリソースリークがあります**

毎秒の `StmtPrepare` コマンドの数は、毎秒の `StmtClose` の数よりもはるかに多く、これはアプリケーションで準備ステートメントのオブジェクトリークが発生していることを示します。

![OLTP-Query](/media/performance/prepared_statement_leaking.png)

- QPSパネルで、赤い太字のラインは失敗したクエリの数を示し、右のY軸は数値を示します。この例では、失敗したクエリの数は毎秒74.6です。
- タイプ別CPSパネルでは、毎秒の `StmtPrepare` コマンドの数は、毎秒の `StmtClose` の数よりもはるかに多く、これは準備ステートメントのオブジェクトリークが発生していることを示しています。
- `Queries Using Plan Cache OPS` パネルでは、`avg-miss` がCPS By Typeパネルの `StmtExecute` とほぼ等しいため、ほとんどすべてのSQL実行が実行計画キャッシュをミスしていることを示しています。

KV/TSOリクエストOPSおよびリクエストのソースによるKVリクエスト時間

- KV/TSOリクエストOPSパネルでは、TiDBからTiKVへのすべてのリクエストの合計を表す `kv request total` のように、秒ごとのKVおよびTSOリクエストの統計を表示できます。TiDBからPDおよびTiKVへのリクエストの種類を観察することで、クラスタ内のワークロードの概要を把握できます。
- KV Request Time By Sourceパネルでは、各KVリクエストタイプとすべてのリクエストソースの時間比率を表示できます。
    - kv request total time：KVおよびTiFlashのリクエストの処理時間の合計です。
    - 各KVリクエストとそれに対応するリクエストソースは、積み上げ棒グラフを形成し、 `external` が通常のビジネスリクエストを識別し、 `internal` が内部アクティビティリクエスト（DDLや自動解析リクエストなど）を識別します。

**例1：ビジーなワークロード**

![TPC-C](/media/performance/tpcc_source_sql.png)

このTPC-Cワークロードでは、

- 秒間のKVリクエストの合計数は79,700です。最も多いリクエストタイプは、リクエスト数の順に `Prewrite`、 `Commit`、 `PessimisticsLock`、 `BatchGet` です。
- KVの処理時間の大部分は `Commit-external_Commit` および `Prewrite-external_Commit` に費やされており、これは外部コミットステートメントからの最も時間を消費するKVリクエストが `Commit` および `Prewrite` であることを示しています。

**例2：解析ワークロード**

![OLTP](/media/performance/internal_stats.png)

このワークロードでは、クラスタで `ANALYZE` ステートメントのみが実行されています。

- 秒間のKVリクエストの合計数は35.5であり、秒間のCopリクエストの数は9.3です。
- KVの処理時間の大部分は `Cop-internal_stats` に費やされており、これは内部の `ANALYZE` 操作からの最も時間を消費するKVリクエストが `Cop` であることを示しています。

#### TiDB CPU、TiKV CPU、およびIOの使用状況
TiDB CPUパネルおよびTiKV CPU/IO MBpsパネルでは、TiDBおよびTiKVの論理CPU使用率およびIOスループットを平均、最大、およびデルタ（最大CPU使用率-最小CPU使用率）を含めて観察できます。これに基づいて、TiDBおよびTiKVの全体的なCPU使用率を判断できます。

- `デルタ`の値に基づいて、TiDBのCPU使用率が不均衡であるか（通常、不均衡なアプリケーション接続に伴う）およびクラスタ内に読み取り/書き込みのホットスポットがあるかどうかを判断できます。
- TiDBおよびTiKVのリソース使用状況の概要を見ると、クラスタ内にリソースのボトルネックがあるかどうか、およびTiKVまたはTiDBがスケールアウトが必要かどうかをすばやく判断できます。

**例1：TiDBリソース使用率の高さ**

このワークロードでは、各TiDBおよびTiKVは8 CPUで構成されています。

![TPC-C](/media/performance/tidb_high_cpu.png)

- TiDBの平均、最大、およびデルタCPU使用率はそれぞれ575%、643%、および136%です。
- TiKVの平均、最大、およびデルタCPU使用率はそれぞれ146%、215%、および118%です。 TiKVの平均、最大、およびデルタI/Oスループットはそれぞれ9.06 MB/s、19.7 MB/s、および17.1 MB/sです。

明らかに、TiDBはCPUをより多く消費しており、これは8 CPUのボトルネックのしきい値に近いです。TiDBをスケールアウトすることをお勧めします。

**例2：TiKVリソース使用率の高さ**

次のTPC-Cのワークロードでは、各TiDBおよびTiKVが16 CPUで構成されています。

![TPC-C](/media/performance/tpcc_cpu_io.png)

- TiDBの平均、最大、およびデルタCPU使用率はそれぞれ883%、962%、および153%です。
- TiKVの平均、最大、およびデルタCPU使用率はそれぞれ1288%、1360%、および126%です。 TiKVの平均、最大、およびデルタI/Oスループットはそれぞれ130 MB/s、153 MB/s、および53.7 MB/sです。

明らかに、TPC-Cは書き込みが多いシナリオであるため、TiKVはCPUをより多く消費しています。パフォーマンスを向上させるためにTiKVをスケールアウトすることをお勧めします。

### クエリ待ち時間の詳細および主要な待ち時間メトリック

待ち時間パネルでは平均値および99パーセンタイルが提供されます。平均値は全体的なボトルネックを特定するのに役立ち、一方、99パーセンタイルまたは999パーセンタイルは、重要な待ち時間の揺れがあるかどうかを判断するのに役立ちます。

#### デュレーション、接続アイドルデュレーション、および接続数

デュレーションパネルには、すべてのステートメントの平均およびP99待ち時間、および各SQLタイプの平均待ち時間が含まれます。接続アイドルデュレーションパネルには、平均およびP99接続アイドルデュレーションが含まれます。接続アイドルデュレーションには次の2つの状態があります。

- in-txn: トランザクション内であるときに前回のSQLの処理から次のSQLステートメントを受信する間隔。
- not-in-txn: トランザクション内でないときに前回のSQLの処理から次のSQLステートメントを受信する間隔。

アプリケーションは同じデータベース接続でトランザクションを実行します。平均クエリ待ち時間と接続アイドルデュレーションを比較することで、TiDBが全体のシステムのボトルネックであるか、またはユーザー応答時間の揺れがTiDBによって引き起こされているかを判断できます。

- アプリケーションワークロードが読み取り専用ではなくトランザクションを含む場合、平均クエリ待ち時間を`avg-in-txn`と比較することで、データベース内外でトランザクションの処理の割合を判断し、ユーザー応答時間のボトルネックを特定できます。
- アプリケーションワークロードが読み取り専用であるかオートコミットモードである場合、平均クエリ待ち時間を`avg-not-in-txn`と比較できます。

実際の顧客シナリオでは、次のようなデータベース外のボトルネックが稀に発生します。

- クライアントサーバーの構成が低すぎてCPUリソースが枯渇している。
- HAProxyがTiDBクラスタープロキシとして使用されており、HAProxyのCPUリソースが枯渇している。
- HAProxyがTiDBクラスタープロキシとして使用されており、高いワークロード下でHAProxyサーバーのネットワーク帯域幅が使い切られている。
- アプリケーションサーバーからデータベースへのネットワークレイテンシが高い。たとえば、パブリッククラウド展開ではアプリケーションとTiDBクラスターが同じ地域にないためにネットワークレイテンシが高い、またはDNSワークロードバランサーとTiDBクラスターが同じ地域にないためにネットワークレイテンシが高い。
- ボトルネックがクライアントアプリケーションにある。アプリケーションサーバーのCPUコアやNumaリソースが十分に利用されていない。たとえば、1つのJVMがTiDBに対して数千のJDBC接続を確立するような場合。

接続数パネルでは、総接続数および各TiDBノード上の接続数を確認し、総接続数が正常か、各TiDBノード上の接続数が不均衡かを判断するのに役立ちます。`active connections`は、アクティブな接続数を示し、これは秒ごとのデータベース時間です。右側のY軸（`disconnection/s`）は、クラスター内の秒ごとの切断数を示し、これを使用してアプリケーションが短い接続を使用しているかどうかを確認できます。

**例1：切断数が高すぎる**

![high disconnection/s](/media/performance/high_disconnections.png)

このワークロードでは：

- すべてのSQLステートメントの平均待ち時間およびP99待ち時間はそれぞれ10.8 msおよび84.1 msです。
- トランザクション内の平均接続アイドル時間 `avg-in-txn` は9.4 msです。
- クラスターへの総接続数は3,700であり、各TiDBノードへの接続数は1,800です。平均アクティブ接続数は40.3であり、これはほとんどの接続がアイドルであることを示しています。 平均 `disonnnection/s` は55.8であり、これはアプリケーションが頻繁に接続および切断を行っていることを示しています。短い接続の動作はTiDBのリソースと応答時間に一定の影響を与えます。

**例2： TiDBはユーザー応答時間のボトルネック**

![TiDB is the Bottleneck](/media/performance/tpcc_duration_idle.png)

このTPC-Cワークロードでは：

- すべてのSQLステートメントの平均待ち時間とP99待ち時間はそれぞれ477 usと3.13 msです。`commit`ステートメント、`insert`ステートメント、および`query`ステートメントの平均待ち時間はそれぞれ2.02 ms、609 us、および468 usです。
- トランザクション内の平均接続アイドル時間 `avg-in-txn` は171 usです。

平均クエリ待ち時間は明らかに `avg-in-txn` よりも大幅に大きいです。これはトランザクションの主なボトルネックがデータベース内にあることを意味します。

**例3：TiDBはユーザー応答時間のボトルネックでない**

![TiDB is not Bottleneck](/media/performance/cloud_query_long_idle.png)

このワークロードでは、平均クエリ待ち時間は1.69 msであり、 `avg-in-txn` は18 msであり、TiDBは平均して1.69 msをトランザクション内でSQLステートメントの処理に費やし、次に18 ms待つ必要があることを示しています。

平均クエリ待ち時間は明らかに `avg-in-txn` よりも遥かに低いです。ユーザー応答時間のボトルネックはTiDBではありません。この例はパブリッククラウド環境で、アプリケーションとデータベースが同じリージョンにないためにネットワークレイテンシが非常に高くなり、接続待ち時間が非常に長いためです。

#### パース、コンパイル、および実行デュレーション

TiDBでは、クエリステートメントの送信から結果の返送までの[典型的な処理フロー](/sql-optimization-concepts.md)があります。

TiDBのSQL処理には、`get token`、`parse`、`compile`、および`execute`の4つの段階があります。

- `get token`: 通常は数マイクロ秒のみであり、無視できます。トークンは、一つのTiDBインスタンスへの接続数が [token-limit](/tidb-configuration-file.md) リミットに達したときにのみ制限されます。
- `parse`: クエリステートメントは抽象構文木（AST）に解析されます。
- `compile`: ASTおよび統計情報に基づいて実行計画がコンパイルされます。`compile`段階には、論理最適化および物理最適化が含まれます。論理最適化は、リレーショナル代数に基づく列の削減などのルールによってクエリプランを最適化します。物理最適化は、統計情報によるコストベースの最適化器によって実行計画のコストを推定し、最小のコストを持つ物理実行計画を選択します。
- `execute`: SQLステートメントの実行にかかる時間。 TiDBはまずグローバルに一意なタイムスタンプTSOを待ちます。その後、実行者は実行計画のオペレータのキー範囲に基づいてTiKV APIリクエストを構築し、TiKVに分散させます。 `execute`時間にはTSO待ち時間、KVリクエスト時間、およびTiDB実行者がデータ処理に費やす時間が含まれます。

アプリケーションが`query`または`StmtExecute` MySQLコマンドインターフェースのみを使用している場合、次の式を使用して平均待ち時間のボトルネックを特定できます。

```
平均クエリデュレーション = 平均Get Token + 平均Parseデュレーション + 平均Compileデュレーション + 平均Executeデュレーション
```

通常、`execute`フェーズが`query`待ち時間の大部分を占めます。ただし、次の場合、`parse`および`compile`フェーズも大部分を占めることがあります。

- `parse`フェーズの待ち時間が長い場合：たとえば、`query`ステートメントが長いと、SQLテキストの解析に多くのCPUが消費されます。
-  `コンパイル` フェーズの長い遅延: TiDBは準備された計画キャッシュにヒットしない場合、すべてのSQL実行に対して実行計画をコンパイルする必要があります。`コンパイル` フェーズの遅延は数ミリ秒または数十ミリ秒、またはそれ以上になることがあります。準備された計画キャッシュにヒットしない場合、`コンパイル` フェーズで論理および物理的な最適化が行われ、CPUおよびメモリを多く消費し、Go Runtime（TiDBは[`Go`](https://go.dev/)で記述されています）に圧力をかけ、他のTiDBコンポーネントのパフォーマンスに影響を及ぼします。効率的なOLTPワークロードの処理にとって準備された計画キャッシュは重要です。

**例1：`コンパイル` フェーズのデータベースのボトルネック**

![コンパイル](/media/performance/long_compile.png)

上記の図では、`parse`、`compile`、および`execute`フェーズの平均時間がそれぞれ17.1マイクロ秒、729マイクロ秒、681マイクロ秒である。`コンパイル` 遅延が高いのは、アプリケーションが`query`コマンドインターフェースを使用し、準備された計画キャッシュを使用できないためです。

**例2：`実行` フェーズのデータベースのボトルネック**

![実行](/media/performance/long_execute.png)

このTPC-Cワークロードでは、`parse`、`compile`、および`execute`フェーズの平均時間がそれぞれ7.39マイクロ秒、38.1マイクロ秒、12.8ミリ秒である。`実行` フェーズは`query`の遅延のボトルネックです。

#### KVおよびTSOリクエスト持続時間

TiDBは`実行`フェーズでPDおよびTiKVとやり取りします。次の図に示すように、SQLリクエストの処理時、TiDBは`parse`および`compile`フェーズに入る前にTSOを要求します。PDクライアントは呼び出し元をブロックせず、「TSFuture」を返し、バックグラウンドでTSOリクエストを非同期に送受信します。PDクライアントがTSOリクエストの処理を完了した後、「TSFuture」を返します。`TSFuture`の保持者は、最終的なTSOを取得するためにWaitメソッドを呼び出す必要があります。TiDBが`parse`および`compile`フェーズを完了した後、2つの状況が発生する可能性があります:

- TSOリクエストが完了している場合、Waitメソッドは利用可能なTSOまたはエラーを即座に返します
- TSOリクエストがまだ完了していない場合、Waitメソッドは、TSOが利用可能になるか、エラーが発生するまでブロックされます（gRPCリクエストが送信されたが結果が返されず、ネットワークの遅延が高い場合）

TSOの待機時間は`TSO WAIT`として記録され、TSOリクエストのネットワーク時間は`TSO RPC`として記録されます。TSO待機が完了した後、通常、TiDBエグゼキュータはTiKVに対して読み込みまたは書き込みリクエストを送信します。

- 一般的なKV読み込みリクエスト：`Get`、`BatchGet`、および`Cop`
- 一般的なKV書き込みリクエスト：2段階コミットの`PessimisticLock`、`Prewrite`および`Commit`

![実行](/media/performance/execute_phase.png)

このセクションの指標は次の3つのパネルに対応しています。

- 平均TiDB KVリクエスト持続時間：TiDBが測定したKVリクエストの平均遅延
- 平均TiKV GRPC持続時間：TiKVでのgRPCメッセージの処理にかかる平均遅延
- PD TSOウェイト/RPC持続時間：TSOリクエスト（RPC）のためのTiDBエグゼキュータTSOウェイト時間およびネットワークの遅延

`平均TiDB KVリクエスト持続時間`と`平均TiKV GRPC持続時間`の関係は以下の通りです:

```
平均TiDB KVリクエスト持続時間 = 平均TiKV GRPC持続時間 + TiDBとTiKVの間のネットワーク遅延 + TiKV gRPC処理時間 + TiDB gRPC処理時間およびスケジューリング遅延
```

`平均TiDB KVリクエスト持続時間`と`平均TiKV GRPC持続時間`の差は、TiDBとTiKVのネットワークトラフィック、ネットワークの遅延、およびリソース使用状況と密接な関係があります。

- 同じデータセンター内：一般的に差は2ミリ秒未満です。
- 同じ地域内の異なる可用ゾーン：一般的に差は5ミリ秒未満です。

**例1：同じデータセンターに配置されたクラスタの負荷が低いケース**

![同じデータセンター](/media/performance/oltp_kv_tso.png)

このワークロードでは、TiDB上の`Prewrite`の平均遅延は925マイクロ秒であり、TiKV内部での`kv_prewrite`処理の平均遅延は720マイクロ秒です。差は約200マイクロ秒であり、同じデータセンター内では通常の値です。平均TSOウェイト遅延は206マイクロ秒で、RPC時間は144マイクロ秒です。

**例2：パブリッククラウドクラスタでの通常のワークロード**

![クラウド環境 ](/media/performance/cloud_kv_tso.png)

この例では、TiDBクラスタが同じ地域内の異なるデータセンターに展開されています。TiDB上の`commit`の平均遅延は12.7ミリ秒であり、TiKV内部での`kv_commit`処理の平均遅延は10.2ミリ秒で、約2.5ミリ秒の差です。平均TSOウェイト遅延は3.12ミリ秒で、RPC時間は693マイクロ秒です。

**例3：パブリッククラウドクラスタでのリソース過負荷**

![クラウド環境, TiDBリソース過負荷](/media/performance/cloud_kv_tso_overloaded.png)

この例では、TiDBクラスタが同じ地域内の異なるデータセンターに展開されており、TiDBのネットワークとCPUリソースが著しく過負荷状態である。TiDB上の`BatchGet`の平均遅延は38.6ミリ秒であり、TiKV内部での`kv_batch_get`処理の平均遅延は6.15ミリ秒です。差は32ミリ秒以上であり、通常の値よりもはるかに高いです。平均TSOウェイト遅延は9.45ミリ秒で、RPC時間は14.3ミリ秒です。

#### ストレージ非同期書き込み持続時間、ストア持続時間、適用持続時間

TiKVは、次の手順で書き込みリクエストを処理します:

- `スケジューラワーカー`は書き込みリクエストを処理し、トランザクションの整合性確認を行い、Raftstoreモジュールに送信するキー値のペアに変換します。
- TiKVのコンセンサスモジュール`Raftstore`は、複数のTiKVから構成されるストレージ層を耐障害性にするためにRaftコンセンサスアルゴリズムを適用します。

    Raftstoreは`ストア`スレッドと`適用`スレッドで構成されています:

    - `ストア`スレッドはRaftメッセージと新しい`提案`を処理します。リーダーノードの`ストア`スレッドは新しい`提案`を受信すると、ローカルRaft DBに書き込み、メッセージを複数のフォロワーノードにコピーします。この`提案`がほとんどのインスタンスで正常に永続化されると、`提案`は正常にコミットされます。
    - `適用`スレッドは、コミットされた`提案`をKV DBに書き込みます。コンテンツがKV DBに正常に書き込まれると、`適用`スレッドは書き込みリクエストの完了を外部に通知します。

![TiKV書き込み](/media/performance/store_apply.png)

`Storage Async Write Duration`メトリックは、書き込みリクエストがraftstoreに入ってからの遅延を記録します。このデータはリクエストごとに収集されます。

`Storage Async Write Duration`メトリックには`ストア持続時間`と`適用持続時間`の2つの部分が含まれており、書き込みリクエストのボトルネックが`ストア`ステップか`適用`ステップかを判断するために次の式を使用できます。

```
平均Storage Async Write Duration = 平均ストア持続時間 + 平均適用持続時間
```

> **注意:**
>
> `ストア持続時間`および`適用持続時間`はv5.3.0以降でサポートされています。

**例1：v5.3.0とv5.4.0で同じOLTPワークロードの比較**

上記の式によると、v5.4.0の書き込み集中型OLTPワークロードのQPSは、v5.3.0と比較して14%高いです:

- v5.3.0: 24.4 ms ≈ 17.7 ms + 6.59 ms
- v5.4.0: 21.4 ms ≈ 14.0 ms + 7.33 ms

v5.4.0で、Raftログのレプリケーションの高速化のためにgPRCモジュールが最適化され、`ストア持続時間`がv5.3.0と比較して低下しています。

v5.3.0:

![v5.3.0](/media/performance/v5.3.0_store_apply.png)

v5.4.0:

![v5.4.0](/media/performance/v5.4.0_store_apply.png)

**例2：ストア持続時間がボトルネックである場合**

上記の式を適用すると、10.1 ms ≈ 9.81 ms + 0.304 msとなります。この結果から、書き込みリクエストの遅延ボトルネックは`ストア持続時間`であることが示されます。

![ストア](/media/performance/cloud_store_apply.png)

#### 提案ログ持続時間、追加ログ持続時間、および適用ログ持続時間

`提案ログ持続時間`、`追加ログ持続時間`、および`適用ログ持続時間`は、raftstore内の重要な操作の遅延メトリックです。これらの遅延はバッチ操作レベルでキャプチャされ、各操作が複数の書き込みリクエストを組み合わせるため、直接`ストア持続時間`および`適用持続時間`に対応するものではありません。
- `Commit Log Duration` と `Append Log Duration` は、`Store` スレッドで実行された操作の時間を記録します。 `Commit Log Duration` には、Raft ログを他の TiKV ノードにコピーする時間（raft-log の永続性を確保するため）が含まれます。通常、`Commit Log Duration` には、リーダーとフォロワーそれぞれの2つの `Append Log Duration` 操作が含まれます。通常、 `Commit Log Duration` は `Append Log Duration` よりもかなり長くなります。これは、前者にはネットワークを介して Raft ログを他の TiKV ノードにコピーする時間が含まれるためです。

- `Apply Log Duration` は、`Apply` スレッドによる `apply` Raft ログの遅延を記録します。

`Commit Log Duration` が長い一般的なシナリオ：

- TiKV のCPUリソースにボトルネックがあり、スケジューリングの遅延が大きい場合
- `raftstore.store-pool-size` が過度に小さすぎるか、大きすぎる場合（過度に大きな値もパフォーマンスの低下を引き起こす可能性があります）
- I/Oの遅延が大きく、 `Append Log Duration` の遅延が高くなっている場合
- TiKV ノード間のネットワーク遅延が大きい場合
- gRPCスレッドの数が少なすぎ、CPU使用率がgRPCスレッド間で均等でない場合

`Apply Log Duration` が長い一般的なシナリオ：

- TiKV のCPUリソースにボトルネックがあり、スケジューリングの遅延が大きい場合
- `raftstore.apply-pool-size` が過度に小さすぎるか、大きすぎる場合（過度に大きな値もパフォーマンスの低下を引き起こす可能性があります）
- I/Oの遅延が大きい場合

**例1：v5.3.0とv5.4.0の同じOLTPワークロードの比較**

v5.4.0におけるライト重視のOLTPワークロードのQPSは、v5.3.0と比較して14%向上しています。次の表は、3つの主要な遅延を比較しています。

| 平均期間 | v5.3.0（ms） | v5.4.0（ms） |
|:----------|:----------|:----------|
| Append Log Duration | 0.27 | 0.303|
| Commit Log Duration | 13 | 8.68 |
| Apply Log Duration | 0.457|0.514 |

v5.4.0では、gRPCモジュールが最適化され、Raftログのレプリケーションが加速されています。これにより、`Commit Log Duration` と `Store Duration` がv5.3.0と比較して短縮されています。

v5.3.0：

![v5.3.0](/media/performance/v5.3.0_commit_append_apply.png)

v5.4.0：

![v5.4.0](/media/performance/v5.4.0_commit_append_apply.png)

**例2：Commit Log Duration がボトルネックである**

![Store](/media/performance/cloud_append_commit_apply.png)

- 平均 `Append Log Duration` = 4.38 ms
- 平均 `Commit Log Duration` = 7.92 ms
- 平均 `Apply Log Duration` = 172 us

`Store` スレッドにとって、`Commit Log Duration` は明らかに `Apply Log Duration` よりも高くなっています。同時に、 `Append Log Duration` は明らかに `Apply Log Duration` よりも高くなっており、 `Store` スレッドにおいてCPUとI/Oの両方でボトルネックになっている可能性が示唆されています。 `Commit Log Duration` と `Append Log Duration` を削減するためのいくつかの方法は次のとおりです：

- TiKVのCPUリソースが十分である場合は、`raftstore.store-pool-size` の値を増やして `Store` スレッドを追加することを検討してください。
- TiDBがv5.4.0以降である場合は、`raft-engine.enable: true` と設定して[`Raft Engine`](/tikv-configuration-file.md#raft-engine) を有効にすることを検討してください。Raft Engineには軽量な実行パスがあります。これにより、一部のシナリオでI/O書き込みとライトの長い遅延が削減されます。
- TiKVのCPUリソースが十分であり、TiDBがv5.3.0以降である場合は、`raftstore.store-io-pool-size: 1` と設定して[`StoreWriter`](/tune-tikv-thread-performance.md#performance-tuning-for-tikv-thread-pools) を有効にすることを検討してください。

## TiDBのバージョンがv6.1.0よりも前の場合、パフォーマンス概要ダッシュボードを使用するためには何をすればよいですか？

v6.1.0以降、Grafanaにはデフォルトで組み込みのパフォーマンス概要ダッシュボードがあります。このダッシュボードはTiDB v4.xおよびv5.xバージョンと互換性があります。TiDBがv6.1.0よりも前の場合、次の図に示すように、[`performance_overview.json`](https://github.com/pingcap/tidb/blob/master/pkg/metrics/grafana/performance_overview.json)を手動でインポートする必要があります：

![Store](/media/performance/import_dashboard.png)