---
title: シャードマージシナリオでのデータマイグレーションのベストプラクティス
summary: シャードマージシナリオでのデータマイグレーションのベストプラクティスを学ぶ。
aliases: ['/docs/tidb-data-migration/dev/shard-merge-best-practices/']
---

# シャードマージシナリオでのデータマイグレーションのベストプラクティス

このドキュメントでは、[TiDBデータマイグレーション](https://github.com/pingcap/dm)（DM）のシャードマージシナリオにおける機能と制限について説明し、アプリケーション（デフォルトの「悲観的」モードが使用されます）のためのデータマイグレーションのベストプラクティスガイドを提供します。

## 別々のデータマイグレーションタスクを使用する

[シャードされたテーブルからデータをマージおよびマイグレーションする](/dm/feature-shard-merge-pessimistic.md#principles) ドキュメントでは、「シャーディンググループ」の定義が示されており、シャーディンググループは、同じダウンストリームテーブルにマージおよびマイグレーションする必要があるすべてのアップストリームテーブルで構成されています。

現在のシャーディングDDLメカニズムには、異なるシャードされたテーブルでのDDL操作によってもたらされたスキーマの変更を調整するための[使用制限](/dm/feature-shard-merge-pessimistic.md#restrictions)があります。これらの制限が予期しない理由で違反された場合は、[DMでシャーディングDDLロックを手動で処理](/dm/manually-handling-sharding-ddl-locks.md) し、場合によってはデータマイグレーションタスク全体をやり直す必要があります。

例外が発生した場合にデータマイグレーションに与える影響を和らげるために、それぞれのシャーディンググループを別々のデータマイグレーションタスクとしてマージおよびマイグレーションすることを推奨しています。**これにより、ほとんどのデータマイグレーションタスクは手動で処理する必要があり、他のデータマイグレーションタスクは影響を受けない可能性があります。**

## シャーディングDDLロックを手動で処理する

[シャードされたテーブルからデータをマージおよびマイグレーションする](/dm/feature-shard-merge-pessimistic.md#principles) ドキュメントから、DMのシャーディングDDLロックは、複数のアップブリンテーブルからダウンストリームへのDDL操作の実行を調整するメカニズムであることが容易に理解できます。

したがって、`shard-ddl-lock`コマンドを使用して`DM-master`上でシャーディングDDLロックを見つけた場合、または`query-status`コマンドを使用していくつかのDMワーカー上で`unresolvedGroups`または`blockingDDLs` を見つけた場合は、`shard-ddl-lock unlock`コマンドを使用してシャーディングDDLロックを手動で解除するのを急ぐべきではありません。

代わりに、以下のようにすることができます：

- 自動的にシャーディングDDLロックを解除する失敗が[リストされた異常シナリオ](/dm/manually-handling-sharding-ddl-locks.md#supported-scenarios)の一つである場合、対応する手動ソリューションに従います。
- サポートされていないシナリオである場合は、データのマージ、マイグレーションをダウンストリームのデータベースとマイグレーションタスクに関連する`dm_meta`情報を空にしてから、全体と増分データレプリケーションを再実行します。

## 複数のシャードされたテーブル間の主キーや一意のインデックスの競合を処理する

複数のシャードされたテーブルからのデータは、主キーや一意のインデックスの競合を引き起こす可能性があります。これらのシャードされたテーブルのシャーディングロジックに基づいてそれぞれの主キーや一意のインデックスを確認する必要があります。以下は、主キーまたは一意のインデックスに関連する3つのケースです：

- シャードキー：通常、同じシャードキーは1つのシャードされたテーブルにのみ存在するため、シャードキーでデータ競合は発生しません。
- オートインクリメント主キー：各シャードされたテーブルのオートインクリメント主キーは個別にカウントされるため、その範囲が重なる可能性があります。この場合は、次のセクション[オートインクリメント主キーの競合を処理する](/dm/shard-merge-best-practices.md#handle-conflicts-of-auto-increment-primary-key) を参照して解決する必要があります。
- その他の主キーや一意のインデックス：これについては、それらをビジネスロジックに基づいて分析する必要があります。データが競合する場合は、次のセクション[オートインクリメント主キーの競合を処理する](/dm/shard-merge-best-practices.md#handle-conflicts-of-auto-increment-primary-key) を参照して解決することもできます。

## オートインクリメント主キーの競合を処理する

このセクションでは、オートインクリメント主キーの競合を処理するための2つの推奨される解決方法を紹介します。

### 列から`PRIMARY KEY`属性を削除する

上ストリームのスキーマが以下のような場合を想定します：

```sql
CREATE TABLE `tbl_no_pk` (
  `auto_pk_c1` bigint(20) NOT NULL,
  `uk_c2` bigint(20) NOT NULL,
  `content_c3` text,
  PRIMARY KEY (`auto_pk_c1`),
  UNIQUE KEY `uk_c2` (`uk_c2`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1
```

以下の要件が満たされている場合：

- `auto_pk_c1`列がアプリケーションに影響を及ぼさず、列の`PRIMARY KEY`属性に依存しない。
- `uk_c2`列が`UNIQUE KEY`属性を持ち、すべての上流のシャードされたテーブルでグローバルに一意である。

この場合、シャードされたテーブルをマージする際に`auto_pk_c1`列によって引き起こされる"ERROR 1062（23000：キー'PRIMARY'に対する重複エントリ '***'）"エラーを修正するために、次の手順を実行できます。

1. フルデータマイグレーションの前に、データマイグレーションをマージして、下流のデータベース用にテーブルを作成し、`auto_pk_c1`列の`PRIMARY KEY`属性を通常のインデックスに変更します。

    ```sql
    CREATE TABLE `tbl_no_pk_2` (
      `auto_pk_c1` bigint(20) NOT NULL,
      `uk_c2` bigint(20) NOT NULL,
      `content_c3` text,
      INDEX (`auto_pk_c1`),
      UNIQUE KEY `uk_c2` (`uk_c2`)
    ) ENGINE=InnoDB DEFAULT CHARSET=latin1
    ```

2. `task.yaml`に次の構成を追加して、オートインクリメント主キーの競合のチェックをスキップします：

    ```yaml
    ignore-checking-items: ["auto_increment_ID"]
    ```

3. フルデータおよび増分データレプリケーションタスクを開始します。

4. `query-status`を実行して、データマイグレーションタスクが正常に処理され、上流のデータがすでに下流のデータベースにマージされ、マイグレーションされたかどうかを確認します。

### 複合主キーを使用する

上流のスキーマが以下のような場合を想定します：

```sql
CREATE TABLE `tbl_multi_pk` (
  `auto_pk_c1` bigint(20) NOT NULL,
  `uuid_c2` bigint(20) NOT NULL,
  `content_c3` text,
  PRIMARY KEY (`auto_pk_c1`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1
```

以下の要件が満たされている場合：

- アプリケーションが`auto_pk_c1`列の`PRIMARY KEY`属性に依存していない。
- `auto_pk_c1`と`uuid_c2`列から構成される複合主キーがグローバルに一意である。
- アプリケーションで複合主キーを使用することができる。

この場合、シャードされたテーブルをマージする際に`auto_pk_c1`列によって引き起こされる"ERROR 1062（23000：キー'PRIMARY'に対する重複エントリ '***'）"エラーを修正するために、次の手順を実行できます。

1. フルデータマイグレーションの前に、データマイグレーションをマージして、下流のデータベース用にテーブルを作成します。`auto_pk_c1`列の`PRIMARY KEY`属性を指定せず、代わりに複合主キーとして`auto_pk_c1`と`uuid_c2`列を使用します。

    ```sql
    CREATE TABLE `tbl_multi_pk_c2` (
      `auto_pk_c1` bigint(20) NOT NULL,
      `uuid_c2` bigint(20) NOT NULL,
      `content_c3` text,
      PRIMARY KEY (`auto_pk_c1`,`uuid_c2`)
    ) ENGINE=InnoDB DEFAULT CHARSET=latin1
    ```

2. フルデータマイグレーションおよび増分データマイグレーションタスクを開始します。

3. `query-status`を実行して、データマイグレーションタスクが正常に処理され、上流のデータがすでに下流のデータベースにマージされ、マイグレーションされたかどうかを確認します。

## 上流RDSにシャードされたテーブルが含まれている場合の特別な処理

上流のデータソースがRDSであり、シャードされたテーブルが含まれている場合、MySQLバイナリログ内のテーブル名はSQLクライアントへの接続時には見えない場合があります。たとえば、上流がUCloud分散データベースの場合、バイナリログ内のテーブル名には付加的なプレフィックス`_0001`が含まれることがあります。そのため、SQLクライアントでの表の名前ではなく、バイナリログ内の表の名前に基づいて[table routing](/dm/dm-table-routing.md)を構成する必要があります。

## 上流でのテーブルの作成/削除

[シャードされたテーブルからデータをマージおよびマイグレーションする](/dm/feature-shard-merge-pessimistic.md#principles) ドキュメントによると、シャーディングDDLロックの調整は、ダウンストリームのデータベースがすべての上流のシャードされたテーブルのDDLステートメントを受信するかどうかに依存します。さらに、DMは現在、上流のシャードされたテーブルを動的に作成したり削除することをサポートしていません。そのため、上流でシャードされたテーブルを作成または削除するには、以下の手順を実行することをお勧めします。

### 上流でシャードされたテーブルを作成する

上流で新しいシャードされたテーブルを作成する必要がある場合は、次の手順を実行します。

1. 全ての実行されたシャーディングDDLの調整が完了するのを待ちます。

2. データマイグレーションタスクを停止するために `stop-task` を実行します。

3. 上流で新しいシャードされたテーブルを作成します。
```
+ {R}
+ {R}
  + {R}
    + {R}
      + {R}
        + {R}
          + {R}
+ {R}
+ {R}
+ {R}
  + {R}
  + {R}
  + {R}
  + {R}
  + {R}
    + {R}
+ {R}
```

```
+ `task.yaml`ファイルの構成が、新しく追加されたシャードされたテーブルを他の既存のシャードされたテーブルと1つのダウンストリームテーブルにマージできるようにすることを確認してください。

+ タスクを開始するには、`start-task`を実行します。

+ データ移行タスクが正常に処理され、アップストリームからのデータが既に結合、移行されたかどうかを確認するには、`query-status`を実行します。

### アップストリームのシャードされたテーブルを削除する

アップストリームでシャードされたテーブルを削除する必要がある場合は、次の手順を実行します。

1. シャードされたテーブルを削除し、[`SHOW BINLOG EVENTS`](https://dev.mysql.com/doc/refman/8.0/en/show-binlog-events.html)を実行して、binlogイベント中の`DROP TABLE`ステートメントに対応する`End_log_pos`を取得し、*Pos-M*とマークします。

2. DMによって処理されたbinlogイベントに対応する位置（`syncerBinlog`）を取得し、*Pos-S*とマークするために、`query-status`を実行します。

3. *Pos-S*が*Pos-M*よりも大きい場合、DMがすべての`DROP TABLE`ステートメントを処理し、テーブルを削除する前のデータがダウンストリームに移行されたことを意味しますので、その後の操作を行うことができます。それ以外の場合は、DMがデータの移行を完了するのを待ちます。

4. タスクを停止するには、`stop-task`を実行します。

5. `task.yaml`ファイルの構成が、アップストリームで削除されたシャードされたテーブルを無視するようになっていることを確認します。

6. タスクを開始するには、`start-task`を実行します。

7. データ移行タスクが正常に処理されたかどうかを確認するには、`query-status`を実行します。

## 速度制限とトラフィックフロー制御

複数のアップストリームMySQLまたはMariaDBインスタンスからのデータが、同じTiDBクラスターにマージされ、ダウンストリームに移行される場合、各アップストリームインスタンスに対応するすべてのDM-workerが、フルおよび増分データ複製を同時に実行します。これは、デフォルトの並行性度（フルデータ移行の`pool-size`および増分データ複製の`worker-count`）が、DM-workerの数を増やすごとに蓄積されることを意味し、ダウンストリームのデータベースに過負荷をかける可能性があります。この場合、TiDBおよびDMの監視メトリクスに基づいて事前のパフォーマンス分析を実施し、各並行性パラメータの値を調整する必要があります。将来的には、DMは部分的に自動化されたトラフィックフロー制御をサポートする予定です。

```