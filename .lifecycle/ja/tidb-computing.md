---
title: TiDB Computing
summary: TiDBデータベースのコンピューティングレイヤーを理解する。

# TiDB Computing

TiKVが提供する分散ストレージを基盤として、TiDBはトランザクション処理とデータ解析の能力を併せ持つ計算エンジンを構築しています。このドキュメントでは、TiDBデータベースのテーブルから(Key, Value)のキー値ペアへのデータマッピングアルゴリズムを紹介し、その後、TiDBがメタデータを管理する方法とTiDB SQLレイヤーのアーキテクチャを説明します。

コンピューティングレイヤーが依存しているストレージソリューションについては、このドキュメントではTiKVの行ベースのストレージ構造のみ紹介しています。OLAPサービスについては、TiDBはTiKVの拡張機能として列ベースのストレージソリューション[TiFlash](/tiflash/tiflash-overview.md)を導入しています。

## テーブルデータのKey-Valueへのマッピング

このセクションでは、TiDBにおけるデータマッピング方法を記載します。ここでマッピングされるデータは、以下の2種類です。

- テーブル内の各行のデータ（以下「テーブルデータ」とします）
- テーブル内のすべてのインデックスのデータ（以下「インデックスデータ」とします）

### テーブルデータのKey-Valueへのマッピング

リレーショナルデータベースでは、テーブルには多くのカラムが存在する場合があります。一行ごとのデータを(Key, Value)のキー値ペアにマッピングするには、Keyの構築方法を考慮する必要があります。まず、OLTPのシナリオでは、1行または複数の行のデータに対する追加、削除、変更、検索などの操作が多く、データベースは迅速にデータ行を読み取る必要があります。そのため、各Keyには迅速に位置を特定できるユニークなID（明示的あるいは暗黙的）が必要です。そのため、テーブル内のすべての行のキーを範囲にエンコードできれば、範囲クエリで全体のテーブルを効率的にスキャンできます。

上記の考慮に基づき、TiDBにおけるテーブルデータのKey-Valueへのマッピングは以下のように設計されています:

- 同じテーブルのデータを簡単に検索できるようにするために、TiDBはテーブルIDを`TableID`で表現したものとして各テーブルに割り当てます。テーブルIDはクラスタ全体で一意の整数です。
- TiDBは、各テーブル内のデータ行に`RowID`で表現した行IDを割り当てます。RowIDも整数であり、テーブル内では一意です。RowIDに関して、TiDBは少しの最適化を行っています。テーブルに整数型のプライマリキーがある場合、TiDBはこのプライマリキーの値をRowIDとして使用します。

各行のデータは、以下の規則に従って(Key, Value)のキー値ペアとしてエンコードされます。

```
Key:   tablePrefix{TableID}_recordPrefixSep{RowID}
Value: [col1, col2, col3, col4]
```

`tablePrefix`と`recordPrefixSep`は、キー空間内の他のデータと区別するために使用される特定の文字列定数です。文字列定数の実際の値については、[マッピング関係の概要](#マッピング関係の概要)で説明されています。

### インデックスデータのKey-Valueへのマッピング

TiDBは、プライマリキーおよび一意制約のあるセカンダリインデックスの両方をサポートしています。テーブルデータのマッピングスキームと同様に、TiDBは`IndexID`で表現したテーブルの各インデックスにインデックスIDを割り当てます。

プライマリキーや一意制約のあるインデックスについては、そのキー値ペアは対応する`RowID`を迅速に特定する必要があるため、以下のようにエンコードされます。

```
Key:   tablePrefix{tableID}_indexPrefixSep{indexID}_indexedColumnsValue
Value: RowID
```

一意制約のない通常のセカンダリインデックスについては、単一のキーが複数の行に対応する可能性があります。そのため、キー値ペアは以下の規則に従ってエンコードされる必要があります。

```
Key:   tablePrefix{TableID}_indexPrefixSep{IndexID}_indexedColumnsValue_{RowID}
Value: null
```

### マッピング関係の概要

上記のエンコード規則において、テーブルデータまたはインデックスデータのKeyエンコードスキームに関わらず、テーブル内のすべての行には同じキープレフィックスがあり、また、インデックスのすべてのデータにも同じプレフィックスがあります。同じプレフィックスのデータは、TiKVのキー空間において一緒に配置されます。そのため、接頭辞の後のエンコーディング比較が同じになるように、接尾辞部分のエンコーディングスキームを注意深く設計することで、テーブルデータまたはインデックスデータをTiKVに順序良く保存することができます。このエンコードスキームを使用することで、テーブルのすべての行データがTiKVのキー空間において`RowID`の順に整列され、特定のインデックスのデータも特定の値によってキー空間内で順次配置されます（`indexedColumnsValue`）。

### Key-Valueマッピング関係の実例

このセクションでは、TiDBのKey-Valueマッピング関係を理解するための簡単な例を示します。TiDBに次のテーブルが存在すると仮定します。

```sql
CREATE TABLE User (
     ID int,
     Name varchar(20),
     Role varchar(20),
     Age int,
     PRIMARY KEY (ID),
     KEY idxAge (Age)
);
```

次のような3行のデータがテーブルに存在すると仮定します。

```
1, "TiDB", "SQL Layer", 10
2, "TiKV", "KV Engine", 20
3, "PD", "Manager", 30
```

それぞれのデータ行は(Key, Value)のキー値ペアにマッピングされ、テーブルには`int`型のプライマリーキーがありますので、`RowID`の値はプライマリーキーの値となります。テーブルIDを`10`と仮定した場合、TiKVに格納されるテーブルデータは以下のようになります。

```
t10_r1 --> ["TiDB", "SQL  Layer", 10]
t10_r2 --> ["TiKV", "KV  Engine", 20]
t10_r3 --> ["PD", " Manager", 30]
```

プライマリーキーに加え、テーブルには一意でない通常のセカンダリインデックス`idxAge`が存在します。`IndexID`が`1`と仮定した場合、TiKVに格納されるインデックスデータは以下のようになります。

```
t10_i1_10_1 --> null
t10_i1_20_2 --> null
t10_i1_30_3 --> null
```

上記の例は、リレーショナルモデルからTiDBのKey-Valueモデルへのマッピングルールと、このマッピングスキームの背後にある考え方を示しています。

## メタデータ管理

TiDBの各データベースとテーブルには、それぞれの定義やさまざまな属性を示すメタデータがあります。この情報も永続化する必要があり、TiDBはこれらの情報もTiKVに格納しています。

各データベースまたはテーブルには一意のIDが割り当てられます。このユニークな識別子は、テーブルデータがKey-Valueにエンコードされる際に、`m_`接頭辞をKeyにエンコードされることでキー値ペアが構築されます。

加えて、TiDBはすべてのテーブルの構造情報の最新のバージョン番号を格納する専用の(Key, Value)のキー値ペアを使用します。このキー値ペアはグローバルであり、DDL操作の状態が変更されるたびにバージョン番号が`1`ずつ増加します。TiDBはこのキー値ペアをPDサーバに永続的に格納し、キーは`/tidb/ddl/global_schema_version`となり、Valueは`int64`型のバージョン番号の値です。また、TiDBはオンラインでスキーマ変更を適用するため、PDサーバに格納されたテーブル構造情報のバージョン番号が変更されないかを定期的に確認するバックグラウンドスレッドを保持しています。このスレッドは、一定の期間内にバージョンの変更を取得できるようにします。

## SQLレイヤー概要

TiDBのSQLレイヤーであるTiDBサーバーは、SQL文をKey-Valueの操作に変換し、その操作を分散Key-Valueストレージ層であるTiKVに転送し、TiKVから返された結果を集約し、最終的にクエリ結果をクライアントに返します。

このレイヤーのノードはステートレスです。これらのノード自体はデータを保持せず、完全に同等です。

### SQLコンピューティング

SQLコンピューティングの最も単純な解決策は、前述の[テーブルデータをKey-Valueにマッピング](#mapping-of-table-data-to-key-value)する方法に説明されているように、SQLクエリをKVクエリにマッピングし、KVインタフェースを通じて対応するデータを取得し、さまざまな計算を実行することです。

たとえば、` select count(*) from user where name = "TiDB"`というSQL文を実行するためには、TiDBはテーブル内のすべてのデータを読み取り、`name`フィールドが`TiDB`であるかどうかを確認し、その後、この行を返します。その過程は以下のとおりです:

1. Key範囲の構築: テーブル内のすべての`RowID`は`[0, MaxInt64)`の範囲にあるため、行データ`Key`のエンコーディング規則に従い、`0`および`MaxInt64`を使用して、左閉区間および右開区間の`[StartKey, EndKey)`範囲を構築します。
2. Key範囲のスキャン: 上記で構築したキー範囲に従って、TiKV内のデータを読み取ります。
3. データのフィルタリング: 読み込まれたデータのそれぞれの行に対して、`name = "TiDB"` の式を計算します。結果が `true` であれば、この行を返します。そうでなければ、この行をスキップします。
4. `Count(*)` の計算: 要件を満たす各行に対して、`Count(*)` の結果を合計します。

**全体のプロセスは以下のように示されます:**

![ナイーブなSQLフロー](/media/tidb-computing-native-sql-flow.jpeg)

この解決策は直感的で実現可能ですが、分散データベースのシナリオでは明らかな問題点があります:

- データをスキャンしながら、各行は少なくとも1つのRPCオーバーヘッドを伴うKV操作を介してTiKVから読み込まれます。データが多い場合、このオーバーヘッドが非常に大きくなる可能性があります。
- すべての行に適用されるわけではありません。条件を満たさないデータは読み込む必要がありません。
- このクエリの返された結果からは、条件に一致する行の数だけが必要であり、それらの行の値ではありません。

### 分散SQL操作

上記の問題を解決するために、計算はストレージノードにできるだけ近い位置で行うべきです。まず、SQL述語条件の `name = "TiDB"` は、ストレージノードにプッシュダウンされて計算されるべきです。そのため、無意味なネットワーク転送を回避するために、有効な行のみが返されます。それから、集計関数 `Count(*)` もプッシュダウンされ、ストレージノードで事前集約が行われ、各ノードは `Count(*)` の結果を返すだけです。SQLレイヤーは各ノードから返された `Count(*)` の結果を合算します。

次の画像は、データが段階的に返される様子を示しています:

![分散SQLフロー](/media/tidb-computing-dist-sql-flow.png)

### SQLレイヤーのアーキテクチャ

前述のセクションでは、SQLレイヤーのいくつかの機能を紹介し、SQLステートメントがどのように処理されるかについて基本的な理解を持ってもらえると嬉しいです。実際には、TiDBのSQLレイヤーはより複雑で、多くのモジュールとレイヤーがあります。以下の図は重要なモジュールと呼び出し関係をリストアップしています:

![tidb sql layer](/media/tidb-computing-tidb-sql-layer.png)

ユーザーのSQLリクエストは、直接または `負荷分散装置` を介してTiDBサーバーに送信されます。TiDBサーバーは `MySQLプロトコルパケット` を解析し、リクエストの内容を取得し、SQLリクエストの構文および意味を解析し、クエリプランを開発および最適化し、クエリプランを実行し、データを取得および処理します。すべてのデータはTiKVクラスターに格納されているため、このプロセスではTiDBサーバーはTiKVとやり取りし、データを取得する必要があります。最後に、TiDBサーバーはユーザーにクエリ結果を返す必要があります。