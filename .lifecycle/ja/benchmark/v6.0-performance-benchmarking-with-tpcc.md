---
title: TiDB TPC-C パフォーマンステストレポート -- v6.0.0 対 v5.4.0
---

# TiDB TPC-C パフォーマンステストレポート -- v6.0.0 対 v5.4.0

## テスト概要

このテストは、TiDB v6.0.0 と v5.4.0 の TPC-C パフォーマンスを、オンライントランザクション処理（OLTP）シナリオで比較することを目的としています。結果によると、v5.4.0 と比較して、v6.0.0 の TPC-C パフォーマンスは 24.20% 向上しています。

## テスト環境（AWS EC2）

### ハードウェア構成

| サービスタイプ | EC2タイプ | インスタンス数 |
|:----------|:----------|:----------|
| PD        | m5.xlarge |     3     |
| TiKV      | i3.4xlarge|     3     |
| TiDB      | c5.4xlarge|     3     |
| TPC-C  | c5.9xlarge|     1     |

### ソフトウェアバージョン

| サービスタイプ | ソフトウェアバージョン  |
| :----------- | :---------------- |
| PD           | v5.4.0 および v6.0.0 |
| TiDB         | v5.4.0 および v6.0.0 |
| TiKV         | v5.4.0 および v6.0.0 |
| TiUP         | 1.9.3             |
| HAProxy      | 2.5.0             |

### パラメータ構成

TiDB v6.0.0 および TiDB v5.4.0 は同じ構成を使用しています。

#### TiDBパラメータ構成

{{< コピー可能 "" >}}

```yaml
log.level: "error"
prepared-plan-cache.enabled: true
tikv-client.max-batch-wait-time: 2000000
```

#### TiKVパラメータ構成

{{< コピー可能 "" >}}

```yaml
pessimistic-txn.pipelined: true
raftdb.allow-concurrent-memtable-write: true
raftdb.max-background-jobs: 4
raftstore.apply-max-batch-size: 2048
raftstore.apply-pool-size: 3
raftstore.store-max-batch-size: 2048
raftstore.store-pool-size: 3
readpool.storage.normal-concurrency: 10
rocksdb.max-background-jobs: 8
server.grpc-concurrency: 6
```

#### TiDBグローバル変数構成

{{< コピー可能 "sql" >}}

```sql
set global tidb_hashagg_final_concurrency=1;
set global tidb_hashagg_partial_concurrency=1;
set global tidb_enable_async_commit = 1;
set global tidb_enable_1pc = 1;
set global tidb_guarantee_linearizability = 0;
set global tidb_enable_clustered_index = 1;
```

#### HAProxy構成 - haproxy.cfg

TiDB で HAProxy を使用する方法の詳細については、[TiDB で HAProxy を使用するためのベストプラクティス]（/best-practices/haproxy-best-practices.md）を参照してください。

{{< コピー可能 "" >}}

```yaml
global                                     # グローバル構成。
   pidfile     /var/run/haproxy.pid        # HAProxyプロセスのPIDをこのファイルに書き込みます。
   maxconn     4000                        # 単一のHAProxyプロセスに対する同時接続の最大数。
   user        haproxy                     # UIDパラメータと同じです。
   group       haproxy                     # GIDパラメータと同じです。専用のユーザーグループが推奨されています。
   nbproc      64                          # デーモン化するときに作成されるプロセス数。複数のプロセスを開始してリクエストを転送する場合は、HAProxyがプロセスをブロックしないよう十分に大きな値にする必要があります。
   daemon                                  # プロセスをバックグラウンドにフォークします。コマンドラインの "-D" 引数と同等です。 "-db" 引数で無効にできます。
defaults                                   # デフォルトの構成。
   log global                              # グローバル構成の設定を継承します。
   retries 2                               # 上流サーバーに接続しようとする再試行の最大数。接続試行回数が値を超えると、バックエンドサーバーは利用できないと見なされます。
   timeout connect  2s                     # バックエンドサーバーへの接続試行が成功するまでの最大時間。サーバーがHAProxyと同じLAN上にある場合は、より短い時間に設定する必要があります。
   timeout client 30000s                   # クライアント側の最大非アクティブ時間。
   timeout server 30000s                   # サーバー側の最大非アクティブ時間。
listen tidb-cluster                        # データベースの負荷分散。
   bind 0.0.0.0:3390                       # 浮動IPアドレスとリスニングポート。
   mode tcp                                # HAProxyはレイヤー4、トランスポート層を使用します。
   balance leastconn                      # 最も少ない接続を持つサーバーが接続を受けます。長時間のセッションが期待されるLDAP、SQL、TSEなどのプロトコルには「leastconn」が推奨されます。HTTPなどの短いセッションを使用するプロトコルではなく、アルゴリズムは動的であり、遅れた開始のためにサーバーの重みが動的に調整される可能性があります。
   server tidb-1 10.9.18.229:4000 check inter 2000 rise 2 fall 3       # 2000ミリ秒ごとにポート4000を検出します。2回成功したら、サーバーは利用可能と見なされます。3回失敗したら、サーバーは利用できないと見なされます。
   server tidb-2 10.9.39.208:4000 check inter 2000 rise 2 fall 3
   server tidb-3 10.9.64.166:4000 check inter 2000 rise 2 fall 3
```

### テストデータの準備

1. TiUP を使用して、TiDB v6.0.0 と v5.4.0 をデプロイします。
2. `tpcc` という名前のデータベースを作成します: `create database tpcc;`。
3. BenchmarkSQL を使用して、TPC-C 5000 Warehouse データをインポートします: `tiup bench tpcc prepare --warehouse 5000 --db tpcc -H 127.0.0.1 -p 4000`。
4. `tiup bench tpcc run -U root --db tpcc --host 127.0.0.1 --port 4000 --time 1800s --warehouses 5000 --threads {{thread}}` コマンドを実行し、HAProxy を介して TiDB 上でストレステストを実行します。各並行性について、テストは30分間実行されます。
5. New Order の tpmC データを結果から抽出します。

## テスト結果

v5.4.0 と比較して、v6.0.0 の TPC-C パフォーマンスは **24.20% 改善**されています。

| スレッド数 | v5.4.0 の tpmC | v6.0.0 の tpmC | tpmC 改善率 (%) |
|:----------|:----------|:----------|:----------|
|50|44822.8|54956.6|22.61|
|100|52150.3|66216.6|26.97|
|200|57344.9|72116.7|25.76|
|400|58675|71254.8|21.44|

![TPC-C](/media/tpcc_v540_vs_v600.png)