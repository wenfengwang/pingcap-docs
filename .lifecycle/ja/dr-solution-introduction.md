---
title: TiDB災害対策ソリューションの概要
summary: TiDBが提供する災害対策ソリューションについて、プライマリ・セカンダリクラスタに基づく災害対策、単一クラスタ内の複数レプリカに基づく災害対策、バックアップとリストアに基づく災害対策などを学びます。
---

# TiDB災害対策ソリューションの概要

このドキュメントでは、TiDBが提供する災害対策（DR）ソリューションについて紹介します。このドキュメントの構成は以下の通りです：

- DRの基本的なコンセプトについて説明します。
- TiDB、TiCDC、およびBackup & Restore（BR）のアーキテクチャを紹介します。
- TiDBが提供するDRソリューションについて説明します。
- これらのDRソリューションを比較します。

## 基本コンセプト

- RTO（復旧時間目標）：システムが災害から復旧するために必要な時間です。
- RPO（復旧ポイント目標）：ビジネスが災害に耐えられる最大のデータ損失量です。

次の図は、これら2つの概念を示しています：

![RTOとRPO](/media/dr/rto-rpo.png)

- エラートレランス目標：災害は異なる地域に影響を与えることがあります。このドキュメントでは、「エラートレランス目標」という用語を使用して、システムが許容できる災害の最大範囲を説明します。
- 地域：このドキュメントでは、地域のDRに焦点を当て、ここで言及されている「地域」とは地理的なエリアまたは都市を指します。

## コンポーネントのアーキテクチャ

具体的なDRソリューションを紹介する前に、このセクションではDRの観点からTiDBコンポーネントのアーキテクチャを紹介します。TiDB、TiCDC、BRのアーキテクチャについて説明します。

### TiDB

![TiDBアーキテクチャ](/media/dr/tidb-architecture.png)

TiDBは、計算とストレージを分離したアーキテクチャで設計されています：

- TiDBはシステムのSQL計算レイヤーです。
- TiKVはシステムのストレージレイヤーであり、行ベースのストレージエンジンです。[領域](/glossary.md#regionpeerraft-group)は、TiKV内のデータをスケジューリングするための基本単位です。領域は、データのソートされた行のコレクションです。領域のデータは少なくとも3つのレプリカに保存され、データの変更はRaftプロトコルを介してログレイヤーでレプリケートされます。
- オプションのコンポーネントであるTiFlashは、解析クエリの高速化に使用される列ベースのストレージエンジンです。データはRaftグループ内のフロート役割を通じて、TiKVからTiFlashにレプリケートされます。

TiDBは、3つの完全なデータレプリカを保存しています。そのため、複数のレプリカに基づくDRも自然に可能です。同時に、TiDBはRaftログを使用してトランザクションログをレプリケートするため、トランザクションログのレプリケーションに基づくDRも提供できます。

### TiCDC

![TiCDCアーキテクチャ](/media/ticdc/cdc-architecture.png)

TiDBの増分データレプリケーションツールであるTiCDCは、PDのetcdを介して高い可用性を実現しています。TiCDCは、複数のCaptureプロセスを介してTiKVノードからデータ変更を取得し、内部でデータ変更をソートおよびマージします。その後、TiCDCは複数のレプリケーションタスクを使用してデータを複数の下流システムにレプリケートします。前述のアーキテクチャ図では次のようになっています：

- TiKVサーバー：上流のデータ変更をTiCDCノードに送信します。TiCDCノードが変更ログが連続していないと判断した場合、アクティブにTiKVサーバーに変更ログの提供をリクエストします。
- TiCDC：複数のCaptureプロセスを実行します。各Captureプロセスは一部のKV変更ログを取得し、取得したデータをソートして異なる下流システムに変更をレプリケートします。

前述のアーキテクチャ図から分かるように、TiCDCのアーキテクチャは、トランザクションログレプリケーションシステムと似ていますが、スケーラビリティが高く、論理的なデータレプリケーションのメリットもあります。そのため、TiCDCはDRシナリオでのTiDBの補完として優れた選択肢です。

### BR

![BRアーキテクチャ](/media/br/br-snapshot-arch.png)

TiDBのバックアップとリストアツールであるBRは、特定の時点を基準に完全なスナップショットバックアップとTiDBクラスタの連続ログバックアップを実行できます。TiDBクラスタが完全に利用できなくなった場合、バックアップファイルを新しいクラスタ（クラスタ2）にリストアすることでサービスを提供することができます。BRは、データセキュリティの最後の手段として考慮されることが多いです。

## ソリューションの紹介

### プライマリ・セカンダリクラスタに基づくDRソリューション

![プライマリ・セカンダリクラスタに基づくDR](/media/dr/ticdc-dr.png)

前述のアーキテクチャには、2つのTiDBクラスタが含まれています。クラスタ1はリージョン1で実行され、読み取りおよび書き込み要求を処理します。クラスタ2はリージョン2で実行され、セカンダリクラスタとして機能します。クラスタ1が災害に見舞われた場合、クラスタ2はサービスを引き継ぎます。データの変更は、TiCDCを使用して2つのクラスタ間でレプリケートされます。このアーキテクチャは、「1：1」DRソリューションとも呼ばれます。

このアーキテクチャは、シンプルで高い可用性を持ち、地域レベルのエラートレランス目標、スケーラブルな書き込み能力、秒レベルのRPO、分レベルまたはそれ以下のRTOを提供します。RPOがゼロである必要がない本番システムの場合、このDRソリューションをおすすめします。詳細については、[プライマリ・セカンダリクラスタに基づくDRソリューション](/dr-secondary-cluster.md)を参照してください。

### 単一クラスタ内の複数レプリカに基づくDRソリューション

![複数レプリカクラスタに基づくDR](/media/dr/multi-replica-dr.png)

前述のアーキテクチャでは、各地域には異なる可用ゾーン（AZ）に配置された2つの完全なデータレプリカがあります。クラスタ全体は3つの地域にまたがっています。リージョン1は読み取りおよび書き込み要求を処理するプライマリリージョンです。リージョン1が災害により完全に使用できなくなった場合、リージョン2をDRリージョンとして使用できます。リージョン3は、過半数プロトコルを満たすためのレプリカです。このアーキテクチャは、「2-2-1」とも呼ばれます。

このソリューションは、地域レベルのエラートレランス、スケーラブルな書き込み能力、ゼロのRPO、分レベルまたはそれ以下のRTOを提供します。RPOがゼロである必要がある本番システムの場合、このDRソリューションを使用することをお勧めします。詳細については、[単一クラスタ内の複数レプリカに基づくDRソリューション](/dr-multi-replica.md)を参照してください。

### TiCDCと複数レプリカに基づくDRソリューション

前述の2つのソリューションは地域レベルのDRを提供します。しかし、複数のリージョンが同時に利用できない場合には機能しません。システムが非常に重要で、エラートレランス目標が複数のリージョンをカバーする必要がある場合は、これら2つのソリューションを組み合わせる必要があります。

![TiCDCをベースにした複数レプリカクラスタDR](/media/dr/ticdc-multi-replica-dr.png)

前述のアーキテクチャでは、2つのTiDBクラスタがあります。クラスタ1には、3つのリージョンにまたがる5つのレプリカがあります。リージョン1には、書き込み要求を処理するプライマリリージョンとして機能する2つのレプリカが含まれています。リージョン2には、リージョン1のDRリージョンとして機能する2つのレプリカがあります。このリージョンでは、遅延に敏感でない読み取りサービスを提供します。リージョン3には、投票用として最後のレプリカが使用されます。

リージョン1とリージョン2のDRクラスタとして、クラスタ2はリージョン3で実行され、3つのレプリカを含んでいます。TiCDCは、クラスタ1からデータをレプリケートします。このアーキテクチャは複雑に見えますが、エラートレランス目標を複数のリージョンに拡大することができます。複数のリージョンが同時に利用できない場合に、RPOがゼロである必要がない場合は、このアーキテクチャを選択することができます。このアーキテクチャは、「2-2-1:1」とも呼ばれます。

もちろん、エラートレランス目標が複数のリージョンであり、RPOがゼロである必要がある場合は、少なくとも5つのリージョンにまたがる9つのレプリカを持つクラスタを作成することも考慮できます。このアーキテクチャは、「2-2-2-2-1」とも呼ばれます。

### BRをベースとしたDRソリューション

![BRベースのクラスタDR](/media/dr/br-dr.png)

このアーキテクチャでは、TiDBクラスタ1がリージョン1に展開されます。BRは定期的にクラスタ1のデータをリージョン2にバックアップし、データの変更ログをリージョン2に連続的にバックアップします。リージョン1が災害に見舞われ、クラスタ1を回復できない場合、バックアップデータとデータの変更ログを使用して新しいクラスタ（クラスタ2）をリージョン2にリストアし、サービスを提供することができます。

BRをベースとしたDRソリューションは、5分以下のRPOと、リストアするデータのサイズによって異なるRTOを提供します。BR v6.5.0の場合、リストアのスピードについては、[スナップショットリストアのパフォーマンスと影響](/br/br-snapshot-guide.md#performance-and-impact-of-snapshot-restore)および[PITRのパフォーマンスと影響](/br/br-pitr-guide.md#performance-and-impact-of-pitr)を参照してください。通常、リージョン間のバックアップの機能は、データセキュリティの最後の手段として考慮され、ほとんどのシステムに必要なソリューションです。詳細については、[BRをベースとしたDRソリューション](/dr-backup-restore.md)を参照してください。

また、v6.5.0以降、BRは[EBSボリュームスナップショットからのTiDBクラスタのリストアをサポート](https://docs.pingcap.com/tidb-in-kubernetes/stable/restore-from-aws-s3-by-snapshot)しています。クラスタがKubernetes上で実行されており、クラスタに影響を与えずにできるだけ早くクラスタをリストアしたい場合は、この機能を使用してシステムのRTOを短縮することができます。

### その他のDRソリューション

前述のDRソリューション以外にも、同じ都市のデュアルセンターシナリオでRPOがゼロである必要がある場合は、DR-AUTO Syncソリューションを使用することもできます。詳細については、[同一都市内の2つのデータセンターの展開](/two-data-centers-in-one-city-deployment.md)を参照してください。

## ソリューションの比較

このセクションでは、このドキュメントで説明されているDRソリューションを比較し、ビジネスニーズに適したDRソリューションを選択することができます。

| DRソリューション | TCO | エラートレランス目標 | RPO | RTO | ネットワークレイテンシの要件 | ターゲットシステム |
| --- | --- | --- | --- | --- | --- | --- |
| シングルクラスター内の複数レプリカに基づくDRソリューション（2-2-1） | 高 | 単一リージョン | 0 | 分単位 | リージョン間の遅延が30ミリ秒未満 | DRおよびレスポンスに特定の要件を持つ本番システム（RPO = 0） |
| プライマリクラスターとセカンダリクラスターに基づくDRソリューション（1:1） | 中 | 単一リージョン | 10秒未満 | 5分未満 | リージョン間の遅延が100ミリ秒未満 | DRおよびレスポンスに特定の要件を持つ本番システム（RPO > 0） |
| TiCDCと複数レプリカに基づくDRソリューション（2-2-1:1） | 高 | 複数リージョン | 10秒未満 | 5分未満 | DRのために複数のレプリカを使用するリージョン間の遅延が30ミリ秒未満。3番目のリージョンおよび他のリージョン間の遅延が100ミリ秒未満 | DRおよびレスポンスに厳格な要件を持つ本番システム |
| BRに基づくDRソリューション | 低 | 単一リージョン | 5分未満 | 時間単位 | 特別な要件なし | RPOが5分未満、RTOが最大1時間まで許容される本番システム |